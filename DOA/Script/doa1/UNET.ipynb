{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sealed-algeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 8, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "\n",
    "def single_conv(in_c, out_c):\n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv2d(in_c, out_c, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True))\n",
    "    return conv\n",
    "\n",
    "def double_conv1(in_c, out_c):\n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv2d(in_c, out_c, kernel_size=(3,2),padding=1 ,stride=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_c, out_c, kernel_size=(3,2),stride=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True))\n",
    "    return conv\n",
    "\n",
    "def double_conv2(in_c, out_c):\n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv2d(in_c, out_c, kernel_size=(3,3),padding=1 ,stride=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_c, out_c, kernel_size=(3,3), padding=1 ,stride=1, bias=True),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.ReLU(inplace=True))\n",
    "    return conv\n",
    "\n",
    "\n",
    "def up_conv1(in_c, out_c):\n",
    "    conv = nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_c, out_c, kernel_size=(2, 3), stride=2))\n",
    "    return conv\n",
    "    \n",
    "def up_conv2(in_c, out_c):\n",
    "    conv = nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_c, out_c, kernel_size=(2,2), stride=2))\n",
    "    return conv\n",
    "\n",
    "\n",
    "class Recurrent_block(nn.Module):\n",
    "    def __init__(self,ch_out,t=2):\n",
    "        super(Recurrent_block,self).__init__()\n",
    "        self.t = t\n",
    "        self.ch_out = ch_out\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "\t\t    nn.BatchNorm2d(ch_out),\n",
    "\t\t\tnn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        for i in range(self.t):\n",
    "\n",
    "            if i==0:\n",
    "                x1 = self.conv(x)\n",
    "            \n",
    "            x1 = self.conv(x+x1)\n",
    "        return x1\n",
    "\n",
    "class RRCNN_block(nn.Module):\n",
    "    def __init__(self,ch_in,ch_out,t=2):\n",
    "        super(RRCNN_block,self).__init__()\n",
    "        self.RCNN = nn.Sequential(\n",
    "            Recurrent_block(ch_out,t=t),\n",
    "            Recurrent_block(ch_out,t=t)\n",
    "        )\n",
    "        self.Conv_1x1 = nn.Conv2d(ch_in,ch_out,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.Conv_1x1(x)\n",
    "        x1 = self.RCNN(x)\n",
    "        return x+x1\n",
    "\n",
    "\n",
    "class Attention_block(nn.Module):\n",
    "    def __init__(self,F_g,F_l,F_int):\n",
    "        super(Attention_block,self).__init__()\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "            )\n",
    "        \n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self,g,x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1+x1)\n",
    "        psi = self.psi(psi)\n",
    "\n",
    "        return x*psi\n",
    "\n",
    "\n",
    "\n",
    "class Att_R2U(nn.Module):\n",
    "    def __init__(self,img_ch=3,output_ch=3,t=2):\n",
    "        super(Att_R2U, self).__init__()\n",
    "        self.max_pool_2x2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.RCNN1 = RRCNN_block(img_ch, 64, t=t)\n",
    "        self.RCNN2 = RRCNN_block(64, 128, t=t)\n",
    "        self.RCNN3 = RRCNN_block(128, 256, t=t)\n",
    "\n",
    "        self.up_trans_1 = up_conv1(256, 128)\n",
    "        self.Att1 = Attention_block(F_g=128,F_l=128,F_int=64)\n",
    "        self.Up_RRCNN1 = RRCNN_block(256, 128,t=t)\n",
    "        \n",
    "        self.up_trans_2 = up_conv2(128, 64)\n",
    "        self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n",
    "        self.Up_RRCNN2 = RRCNN_block(128, 64,t=t)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.out = nn.Conv2d(\n",
    "            in_channels=64,\n",
    "            out_channels=output_ch,\n",
    "            kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "    def forward(self, image):\n",
    "        # encoder\n",
    "        # print(\"Input Image            => \", image.size())\n",
    "        # print(\"Encoder =================\")\n",
    "        x1 = self.RCNN1(image)\n",
    "        # print(\"Conv3x2, S1, P1        => \", x1.size())\n",
    "        x2 = self.max_pool_2x2(x1)\n",
    "        # print(\"max_pool_2x1           => \", x2.size())\n",
    "        x3 = self.RCNN2(x2)\n",
    "        x3 = self.dropout(x3)\n",
    "        # print(\"Conv3x3, S1, P1        => \", x3.size())\n",
    "        x4 = self.max_pool_2x2(x3)\n",
    "        # print(\"max_pool_2x1           => \", x4.size())\n",
    "        x5 = self.RCNN3(x4)\n",
    "        x5 = self.dropout(x5)\n",
    "        # print(\"Conv3x3, S1, P1        => \", x5.size())\n",
    "        \n",
    "        \n",
    "        # decoder\n",
    "        # print(\"Decoder =================\")\n",
    "        x = self.up_trans_1(x5)\n",
    "        # print(\"up_trans_1x18, S3, P0  => \", x.size())\n",
    "        x3 = nn.functional.interpolate(x3, (x.size()[2], x.size()[3]))\n",
    "        x3 = self.Att1(g=x,x=x3)\n",
    "        x = self.Up_RRCNN1(torch.cat([x, x3], 1))\n",
    "        x = self.dropout(x)\n",
    "        # print(\"up_conv_3x3, S1, P1    => \", x.size())\n",
    "\n",
    "        x = self.up_trans_2(x)\n",
    "        # print(\"up_trans_2x2, S2, P0   => \", x.size())\n",
    "        x1 = nn.functional.interpolate(x1, (x.size()[2], x.size()[3]))\n",
    "        x1 = self.Att2(g=x,x=x1)\n",
    "        x = self.Up_RRCNN2(torch.cat([x, x1], 1))\n",
    "        x = self.dropout(x)\n",
    "        # print(\"up_conv_2x3, s1, p1    => \", x.size())\n",
    "        # output\n",
    "        x = self.out(x)\n",
    "#         print(x.size())\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "#     print(\"start\")\n",
    "    image = torch.rand(1, 3, 8, 10)\n",
    "    model = Att_R2U()\n",
    "    print(model(image).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "breeding-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np \n",
    "import math\n",
    "import pandas as pd\n",
    "import cmath\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np \n",
    "import math\n",
    "import pandas as pd\n",
    "import cmath\n",
    "\n",
    "#from unet import UNet\n",
    "# from auto import encoder, decoder\n",
    "\n",
    "from collections import OrderedDict\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "#==========================================================================\n",
    "# For Plotting loss graph\n",
    "# Bokeh\n",
    "from bokeh.io import curdoc\n",
    "from bokeh.layouts import column\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.plotting import figure\n",
    "\n",
    "from functools import partial\n",
    "from threading import Thread\n",
    "from tornado import gen\n",
    "# from AttRCNN_UNet import Att_R2U\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)\n",
    "import sys\n",
    "# from dataloader import norm\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sys import getsizeof\n",
    "# import wandb\n",
    "# import logging\n",
    "# logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "common-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_list = []\n",
    "test_dataset_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac12164f-16ed-44e0-a230-657fadf5f226",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1  = sio.loadmat(\"../SNS_dataset/400/DOA3/SNR_SNS_00_3_400.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b34c2286-017b-401b-b388-d379a95f51b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'DOA', 'SNR_label', 'SNS_data', 'accuracy_sns', 'err_sns'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "188c9eef-3cec-4959-877a-eb304c82effd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09799]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['accuracy_sns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "proved-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1  = sio.loadmat(\"../SNS_dataset/100/DOA4/SNR_SNS_00_4.mat\")\n",
    "df2  = sio.loadmat(\"../SNS_dataset/100/DOA4/SNR_SNS_10_4.mat\")\n",
    "df3  = sio.loadmat(\"../SNS_dataset/100/DOA4/SNR_SNS_20_4.mat\")\n",
    "df4  = sio.loadmat(\"../SNS_dataset/100/DOA4/SNR_SNS_30_4.mat\")\n",
    "df5  = sio.loadmat(\"../SNS_dataset/100/DOA4/SNR_SNS_40_4.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71c01e51-e500-4985-b122-d8227b88fc49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 10, 100000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['SNS_data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5220d4cf-95e3-4cf3-a765-1be696986d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5795b503-7b4d-495c-bb71-2f9237f64a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(df):\n",
    "    # print(df[\"DOA\"].shape)\n",
    "    # print(df['NS_data'].shape)\n",
    "    transp = np.transpose(df['SNS_data'], (2, 0, 1))\n",
    "    new = np.zeros((100000, 3, 8, 10))\n",
    "    for i in range(0, transp.shape[0]):\n",
    "        for j in range(0, transp.shape[1]):\n",
    "            for k in range(0, transp.shape[2]):\n",
    "                new[i][0][j][k] = transp[i][j][k].real\n",
    "                new[i][1][j][k] = transp[i][j][k].imag\n",
    "                new[i][2][j][k] = cmath.phase(transp[i][j][k])\n",
    "\n",
    "    max_r =  -10000000000000\n",
    "    min_r = 10000000000000\n",
    "    max_i =  -10000000000000\n",
    "    min_i = 10000000000000\n",
    "    max_p =  -10000000000000\n",
    "    min_p = 10000000000000\n",
    "\n",
    "    for i in range(0, new.shape[0]):\n",
    "        for j in range(0, new.shape[1]):\n",
    "            for k in range(0, new.shape[2]):\n",
    "                if new[i][0][j][k] > max_r :\n",
    "                    max_r = new[i][0][j][k]\n",
    "                if new[i][0][j][k] < min_r:\n",
    "                    min_r = new[i][0][j][k]\n",
    "                if new[i][1][j][k] > max_i :\n",
    "                    max_i = new[i][1][j][k]\n",
    "                if new[i][1][j][k] < min_i:\n",
    "                    min_i = new[i][1][j][k]\n",
    "                if new[i][2][j][k] > max_p :\n",
    "                    max_p = new[i][2][j][k]\n",
    "                if new[i][2][j][k] < min_p:\n",
    "                    min_p = new[i][2][j][k]\n",
    "    print(\"St\")\n",
    "    print(max_r, max_i, max_p, min_r, min_i, min_p)\n",
    "\n",
    "    ll = []\n",
    "    ll.append(max_r)\n",
    "    ll.append(max_i)\n",
    "    ll.append(max_p)\n",
    "    ll.append(min_r)\n",
    "    ll.append(min_i)\n",
    "    ll.append(min_p)\n",
    "    return ll\n",
    "\n",
    "# import glob\n",
    "\n",
    "# files = glob.glob(\"../SNS_dataset/DOA3/*.mat\")\n",
    "# for i in files:\n",
    "#     norm(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "previous-clock",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = [df1, df2, df3, df4, df5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e837e42-9883-4f7d-ad93-8bffb0bd0005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5acd579-981a-44da-8d73-ff98b1b0cd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "St\n",
      "2.0127047828948776 2.045552062608406 3.141586435905599 -1.8110469693044937 -1.755851519284219 -3.141590575962246\n",
      "St\n",
      "1.4372812259740477 1.3972742207022322 3.1415917612098108 -1.3055565705732592 -1.5644204774975725 -3.1415915006569275\n",
      "St\n",
      "1.4280639175130034 1.2152126579974867 3.141592308830876 -1.3717195836763387 -1.3308847752497681 -3.141592413658264\n",
      "St\n",
      "1.4711718668788916 1.3229705661341953 3.141591746158677 -1.3430478930638148 -1.2021011090986107 -3.141591243785184\n",
      "St\n",
      "1.330725729082957 1.4261281253268836 3.141590132675938 -1.176012626277012 -1.294679573158777 -3.1415910727491974\n"
     ]
    }
   ],
   "source": [
    "norm_list = [norm(i) for i in df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "driving-highway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 10, 100000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df1[\"SNS_data\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cross-intelligence",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_dataset_list = []\n",
    "new_test_dataset_list = []\n",
    "train_dataset_list_label = []\n",
    "test_dataset_list_label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "formed-medicine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df):\n",
    "    data = np.transpose(df['SNS_data'], (2, 0, 1))\n",
    "    label = df['DOA']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.05, random_state=42)\n",
    "    new_train_dataset_list.extend(X_train)\n",
    "    new_test_dataset_list.append(X_test.tolist())\n",
    "    train_dataset_list_label.extend(y_train)\n",
    "    test_dataset_list_label.append(y_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "unexpected-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in df:\n",
    "    create_dataset(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "qualified-mixture",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df\n",
    "del df1\n",
    "del df2\n",
    "del df3\n",
    "del df4\n",
    "del df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fabulous-uncertainty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "475000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_train_dataset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3472d60-09d2-4c1c-8d53-7c87087ef56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0127047828948776"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(norm_list[0][0], norm_list[1][0], norm_list[2][0], norm_list[3][0], norm_list[4][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5db0a605-0ab4-47e4-9e74-bc12920e7cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, data in enumerate(new_train_dataset_list):\n",
    "    max_r = max(norm_list[0][0], norm_list[1][0], norm_list[2][0], norm_list[3][0], norm_list[4][0])\n",
    "    max_i = max(norm_list[0][1], norm_list[1][1], norm_list[2][1], norm_list[3][1], norm_list[4][1])\n",
    "    max_p = max(norm_list[0][2], norm_list[1][2], norm_list[2][2], norm_list[3][2], norm_list[4][2])\n",
    "    min_r = min(norm_list[0][3], norm_list[1][3], norm_list[2][3], norm_list[3][3], norm_list[4][3])\n",
    "    min_i = min(norm_list[0][4], norm_list[1][4], norm_list[2][4], norm_list[3][4], norm_list[4][4])\n",
    "    min_p = min(norm_list[0][5], norm_list[1][5], norm_list[2][5], norm_list[3][5], norm_list[4][5])\n",
    "#     print(type((data[0][0])))\n",
    "    new = np.zeros((3, 8, 10))\n",
    "#     print(type(new[0][0][0]))\n",
    "    for j in range(0, data.shape[0]):\n",
    "        for k in range(0, data.shape[1]):\n",
    "            new[0][j][k] =  (data[j][k].real  - min_r)/(max_r-min_r)\n",
    "            new[1][j][k] =  (data[j][k].imag - min_i)/(max_i-min_i)\n",
    "            new[2][j][k] = (cmath.phase(data[j][k]) - min_p)/ (max_p - min_p)\n",
    "    new_train_dataset_list[idx] = new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47db8d1e-362e-469a-b9da-3827588119bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, data in enumerate(new_test_dataset_list):\n",
    "    for i, ndata in enumerate(data):\n",
    "        max_r = max(norm_list[0][0], norm_list[1][0], norm_list[2][0], norm_list[3][0], norm_list[4][0])\n",
    "        max_i = max(norm_list[0][1], norm_list[1][1], norm_list[2][1], norm_list[3][1], norm_list[4][1])\n",
    "        max_p = max(norm_list[0][2], norm_list[1][2], norm_list[2][2], norm_list[3][2], norm_list[4][2])\n",
    "        min_r = min(norm_list[0][3], norm_list[1][3], norm_list[2][3], norm_list[3][3], norm_list[4][3])\n",
    "        min_i = min(norm_list[0][4], norm_list[1][4], norm_list[2][4], norm_list[3][4], norm_list[4][4])\n",
    "        min_p = min(norm_list[0][5], norm_list[1][5], norm_list[2][5], norm_list[3][5], norm_list[4][5])\n",
    "        new = np.zeros((3, 8, 10))\n",
    "        for j in range(0, 8):\n",
    "            for k in range(0, 10):\n",
    "                new[0][j][k] =  (ndata[j][k].real  - min_r)/(max_r-min_r)\n",
    "                new[1][j][k] =  (ndata[j][k].imag - min_i)/(max_i-min_i)\n",
    "                new[2][j][k] = (cmath.phase(ndata[j][k]) - min_p)/ (max_p - min_p)\n",
    "        new_test_dataset_list[idx][i] = new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a962c9cc-b765-40f8-8c68-fc1b8d27178c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train, test, batch_size, train_bool=True):\n",
    "    class DOA_dataset(Dataset):\n",
    "        def __init__(self, train, test):\n",
    "            self.x = torch.from_numpy(np.array(train))\n",
    "            self.y = torch.from_numpy(np.asarray(test))\n",
    "            self.n_sample = len(self.y)\n",
    "        def __getitem__(self, index):\n",
    "            return self.x[index], self.y[index]\n",
    "        def __len__(self):\n",
    "            return self.n_sample\n",
    "\n",
    "\n",
    "    dataset = DOA_dataset(train, test)\n",
    "    \n",
    "\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=train_bool)\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10d8f6b3-5ed0-4fb0-a690-3b63a0b463db",
   "metadata": {},
   "outputs": [],
   "source": [
    "doa2_train_loader = get_data(new_train_dataset_list, train_dataset_list_label, 64, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23363836-0597-40a6-9e2d-490bf17a8606",
   "metadata": {},
   "outputs": [],
   "source": [
    "del new_train_dataset_list\n",
    "del train_dataset_list_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "340bcf9d-3c26-45e8-8ddf-eccf33fb19e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57058d96-7dbb-4945-a778-5cb4b50e41fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "for idx, data in enumerate(new_test_dataset_list):\n",
    "    print(type(data))\n",
    "    f = get_data(data, test_dataset_list_label[idx], 128, False)\n",
    "    test_dataset_list.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7fb01ccf-99f5-4c5f-a431-0ae4ddc4249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del new_test_dataset_list\n",
    "del new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ecf8845-dc32-4ac2-9059-4b27cd66af11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytorch_metric_learning import losses, miners, distances, reducers, testers\n",
    "# from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
    "# distance = distances.CosineSimilarity()\n",
    "# reducer = reducers.ThresholdReducer(low = 0)\n",
    "# loss_func = losses.TripletMarginLoss(margin = 0.2, distance = distance, reducer = reducer)\n",
    "# mining_func = miners.TripletMarginMiner(margin = 0.2, distance = distance, type_of_triplets = \"semihard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ac8e4e8-af2d-4c2a-93a5-f20f09d4c17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(model, loss_func, mining_func, device, train_loader, optimizer, epoch):\n",
    "#     model.train()\n",
    "#     for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "#         data, labels = Variable(data.cuda()), Variable(labels.cuda())\n",
    "#         optimizer.zero_grad()\n",
    "# #         image = torch.rand(1, 3, 8, 100)\n",
    "#         embeddings = model(data.float())\n",
    "# #         embeddings = embeddings.reshape(embeddings.size(0), 181)\n",
    "# #         labels = torch.zeros([64, 1]).cuda()\n",
    "#         print(embeddings.size(), data.size())\n",
    "#         indices_tuple = mining_func(embeddings,data.float())\n",
    "#         loss = loss_func(embeddings, labels, indices_tuple)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         if batch_idx % 1400 == 0:\n",
    "#             print(\"Epoch {} Iteration {}: Loss = {}, Number of mined triplets = {}\".format(epoch, batch_idx, loss, mining_func.num_triplets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee4cb4c1-ff39-4bdd-a2cb-39db667ffc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ### convenient function from pytorch-metric-learning ###\n",
    "# def get_all_embeddings(dataset, model):\n",
    "#     tester = testers.BaseTester()\n",
    "#     return tester.get_all_embeddings(dataset, model)\n",
    "\n",
    "# # def test(testloader, model):\n",
    "# #     model.eval()\n",
    "# #     validation_loss = 0\n",
    "# #     correct = 0\n",
    "# #     total = 0\n",
    "# #     with torch.no_grad():\n",
    "# #         for features, labels in testloader:\n",
    "# #             features, labels = Variable(features.cuda()), Variable(labels.cuda())\n",
    "# #             enn = autoencoder(features.float())\n",
    "# #             auto_outputs = torch.transpose(enn, 2, 3)\n",
    "# #             auto_outputs = torch.reshape(auto_outputs, (auto_outputs.shape[0], 181, 1))\n",
    "# #             loss = criterion(auto_outputs.cuda(), labels.type(torch.LongTensor).cuda())\n",
    "\n",
    "# #             _, pred = torch.max(auto_outputs, 1)\n",
    "# #             total+= labels.reshape(-1).size(0)\n",
    "# #             correct+=(pred.reshape(-1).cuda() == labels.reshape(-1)).sum().item()\n",
    "# #             validation_loss += loss.item()\n",
    "# # #             wandb.log({\"Validation Acc \"+str(val_data):(100*(correct/total)),\"Validation Loss \"+str(val_data):( validation_loss/len(test_dataset_list[val_data]))})\n",
    "# #     print(val_data*10, \"dB SNR is validated\")\n",
    "# # #     vl1[val_data].append((100*(correct/total)))\n",
    "# #     print(\"Validationloss: {}\".format( validation_loss/len(test_dataset_list[val_data])), \" ---- Validation Acc: {}\".format(100*(correct/total)))\n",
    "# # print(\"\\n\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6faa8f4b-5d81-45a9-8a52-2a7e35355ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# device = torch.device(\"cuda\")\n",
    "# autoencoder = Att_R2U()\n",
    "# model = autoencoder.cuda()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ### pytorch-metric-learning stuff ###\n",
    "# distance = distances.CosineSimilarity()\n",
    "# reducer = reducers.ThresholdReducer(low = 0)\n",
    "# loss_func = losses.TripletMarginLoss(margin = 0.2, distance = distance, reducer = reducer) #losses.NTXentLoss(temperature=0.07) \n",
    "# mining_func = miners.TripletMarginMiner(margin = 0.2, distance = distance, type_of_triplets = \"semihard\")\n",
    "# accuracy_calculator = AccuracyCalculator(include = (\"precision_at_1\",), k = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4b0e0e4-b736-40e8-9c00-fd3c4efde593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(0, 100):\n",
    "# #     for data in range(0, len(train_dataset_list)):\n",
    "# #         print(\"Training has started for \", str(data*10), \"dB SNR\" )\n",
    "#     train(model, loss_func, mining_func, device, doa2_train_loader, optimizer, epoch+1)\n",
    "# #     for val_data in range(0, len(test_dataset_list)):\n",
    "# #         print(\"Validation has started for \", str(val_data*10), \"dB SNR\" )\n",
    "# #         test(train_dataset_list[val_data], test_dataset_list[val_data], model, accuracy_calculator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac599c7b-a240-4ece-908a-89300f1228ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "901ddd85-b8e2-4aa3-ae2a-58ddcc79a451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out torch.Size([64, 3, 8, 10])\n",
      "features torch.Size([64, 3, 8, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iiitd/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'criterion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-69b62bb2ea93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'criterion' is not defined"
     ]
    }
   ],
   "source": [
    "for j,(features, labels) in enumerate(doa2_train_loader, 0):\n",
    "    features, labels = Variable(features), Variable(labels)\n",
    "    out = model(features.float())\n",
    "    print(\"out\", out.size())\n",
    "    print(\"features\", features.size())\n",
    "    out = F.sigmoid(out)\n",
    "    loss = criterion(out, features.float())\n",
    "    print(loss)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1373c62-5466-45bb-833b-1f8c5d3759dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = torch.rand(64, 3, 8, 10)\n",
    "model = Att_R2U()\n",
    "print(model(image).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a06b6d81-d188-40e2-8280-0a71a487e62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.modules.loss._WeightedLoss):\n",
    "    def __init__(self, weight=None, gamma=2,reduction='mean'):\n",
    "        super(FocalLoss, self).__init__(weight,reduction=reduction)\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight #weight parameter will act as the alpha parameter to balance class weights\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        ce_loss = F.cross_entropy(input, target,reduction=self.reduction,weight=self.weight)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n",
    "        return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f8b389-a5c9-433b-95d2-3e0598608384",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pytorch-metric-learning[with-hooks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f762850-f40e-4f37-a32a-8455eb776ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_metric_learning import losses, miners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829ef35e-faa2-4978-b84f-fcc5f5611bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = losses.CrossBatchMemory(loss = losses.NTXentLoss(temperature = 0.1),\n",
    "                                  embedding_size = 128,\n",
    "                                  memory_size = memory_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5f13b8d2-9fdd-473e-a342-cd003f1ed4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Att_R2U()\n",
    "\n",
    "num_epochs = 50\n",
    "doa = 100\n",
    "weights_dir = \"./doa_weights/\"\n",
    "\n",
    "# autoencoder = ResNet18()\n",
    "criterion = nn.BCELoss()\n",
    "focal_criterion = FocalLoss()\n",
    "# if ('SNS_DOA_{}_model.pth'.format(doa) in [f for f in listdir(weights_dir) if isfile(join(weights_dir, f))]):\n",
    "#     print(\"Pre-trained available for DOA_{}_model.pth\".format(doa))\n",
    "#     autoencoder = torch.load(os.path.join(weights_dir, 'SNS_DOA_{}_model.pth'.format(doa)))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "\tprint(torch.cuda.get_device_name(0))\n",
    "\tclassification_model = autoencoder.cuda()\n",
    "\toptimizer = optim.AdamW(classification_model.parameters(), lr=0.01, weight_decay=1e-6)\n",
    "\tcriterion = criterion.cuda()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\", factor=0.05, patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b8b3d7-859c-42ed-bf82-af5b560a7c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0faa4a19-7e9a-4c9a-84b6-21109d5ed746",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_res = {\n",
    "    \"training\": [],\n",
    "    0: [],\n",
    "    10: [],\n",
    "    20: [],\n",
    "    30: [],\n",
    "    40: []\n",
    "}\n",
    "loss_res = {\n",
    "    \"training\": [],\n",
    "    0: [],\n",
    "    10: [],\n",
    "    20: [],\n",
    "    30: [],\n",
    "    40: []\n",
    "}\n",
    "mae_res = {\n",
    "    \"training\": [],\n",
    "    0: [],\n",
    "    10: [],\n",
    "    20: [],\n",
    "    30: [],\n",
    "    40: []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d0a803a-5cc2-4c5e-830d-eac4f7ae6565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Starts !!!!!!!\n",
      "Epoch [1/50], Training Loss: 19.5881\n",
      "SNR [0dB], Validation Loss: 52.1565\n",
      "SNR [10dB], Validation Loss: 52.1571\n",
      "SNR [20dB], Validation Loss: 52.1093\n",
      "SNR [30dB], Validation Loss: 52.1469\n",
      "SNR [40dB], Validation Loss: 52.1230\n",
      "\n",
      "\n",
      "Epoch [2/50], Training Loss: 52.1450\n",
      "SNR [0dB], Validation Loss: 52.1565\n",
      "SNR [10dB], Validation Loss: 52.1571\n",
      "SNR [20dB], Validation Loss: 52.1093\n",
      "SNR [30dB], Validation Loss: 52.1469\n",
      "SNR [40dB], Validation Loss: 52.1230\n",
      "\n",
      "\n",
      "Epoch [3/50], Training Loss: 51.3436\n",
      "SNR [0dB], Validation Loss: 51.3163\n",
      "SNR [10dB], Validation Loss: 51.2768\n",
      "SNR [20dB], Validation Loss: 51.2706\n",
      "SNR [30dB], Validation Loss: 51.2954\n",
      "SNR [40dB], Validation Loss: 51.2524\n",
      "\n",
      "\n",
      "Epoch [4/50], Training Loss: 50.4183\n",
      "SNR [0dB], Validation Loss: 50.0018\n",
      "SNR [10dB], Validation Loss: 49.9844\n",
      "SNR [20dB], Validation Loss: 50.0155\n",
      "SNR [30dB], Validation Loss: 49.9841\n",
      "SNR [40dB], Validation Loss: 49.9926\n",
      "\n",
      "\n",
      "Epoch [5/50], Training Loss: 50.0921\n",
      "SNR [0dB], Validation Loss: 50.1923\n",
      "SNR [10dB], Validation Loss: 50.1947\n",
      "SNR [20dB], Validation Loss: 50.1892\n",
      "SNR [30dB], Validation Loss: 50.1958\n",
      "SNR [40dB], Validation Loss: 50.1926\n",
      "\n",
      "\n",
      "Epoch [6/50], Training Loss: 50.0574\n",
      "SNR [0dB], Validation Loss: 49.8814\n",
      "SNR [10dB], Validation Loss: 49.9206\n",
      "SNR [20dB], Validation Loss: 49.9102\n",
      "SNR [30dB], Validation Loss: 49.9235\n",
      "SNR [40dB], Validation Loss: 49.9355\n",
      "\n",
      "\n",
      "Epoch [7/50], Training Loss: 49.8694\n",
      "SNR [0dB], Validation Loss: 49.9948\n",
      "SNR [10dB], Validation Loss: 49.9760\n",
      "SNR [20dB], Validation Loss: 49.9983\n",
      "SNR [30dB], Validation Loss: 50.0180\n",
      "SNR [40dB], Validation Loss: 50.0091\n",
      "Epoch     7: reducing learning rate of group 0 to 5.0000e-04.\n",
      "\n",
      "\n",
      "Epoch [8/50], Training Loss: 49.9948\n",
      "SNR [0dB], Validation Loss: 49.9948\n",
      "SNR [10dB], Validation Loss: 49.9760\n",
      "SNR [20dB], Validation Loss: 49.9983\n",
      "SNR [30dB], Validation Loss: 50.0180\n",
      "SNR [40dB], Validation Loss: 50.0091\n",
      "\n",
      "\n",
      "Epoch [9/50], Training Loss: 49.9980\n",
      "SNR [0dB], Validation Loss: 49.9923\n",
      "SNR [10dB], Validation Loss: 49.9857\n",
      "SNR [20dB], Validation Loss: 50.0100\n",
      "SNR [30dB], Validation Loss: 49.9955\n",
      "SNR [40dB], Validation Loss: 49.9932\n",
      "\n",
      "\n",
      "Epoch [10/50], Training Loss: 50.0009\n",
      "SNR [0dB], Validation Loss: 49.9713\n",
      "SNR [10dB], Validation Loss: 49.9852\n",
      "SNR [20dB], Validation Loss: 49.9859\n",
      "SNR [30dB], Validation Loss: 49.9856\n",
      "SNR [40dB], Validation Loss: 49.9804\n",
      "\n",
      "\n",
      "Epoch [11/50], Training Loss: 49.9966\n",
      "SNR [0dB], Validation Loss: 50.0046\n",
      "SNR [10dB], Validation Loss: 49.9948\n",
      "SNR [20dB], Validation Loss: 50.0100\n",
      "SNR [30dB], Validation Loss: 50.0064\n",
      "SNR [40dB], Validation Loss: 49.9919\n",
      "\n",
      "\n",
      "Epoch [12/50], Training Loss: 49.9988\n",
      "SNR [0dB], Validation Loss: 49.9416\n",
      "SNR [10dB], Validation Loss: 49.9302\n",
      "SNR [20dB], Validation Loss: 49.9594\n",
      "SNR [30dB], Validation Loss: 49.9458\n",
      "SNR [40dB], Validation Loss: 49.9430\n",
      "\n",
      "\n",
      "Epoch [13/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9423\n",
      "SNR [10dB], Validation Loss: 49.9310\n",
      "SNR [20dB], Validation Loss: 49.9598\n",
      "SNR [30dB], Validation Loss: 49.9467\n",
      "SNR [40dB], Validation Loss: 49.9444\n",
      "Epoch    13: reducing learning rate of group 0 to 2.5000e-05.\n",
      "\n",
      "\n",
      "Epoch [14/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9633\n",
      "SNR [10dB], Validation Loss: 49.9530\n",
      "SNR [20dB], Validation Loss: 49.9821\n",
      "SNR [30dB], Validation Loss: 49.9665\n",
      "SNR [40dB], Validation Loss: 49.9634\n",
      "\n",
      "\n",
      "Epoch [15/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9632\n",
      "SNR [10dB], Validation Loss: 49.9529\n",
      "SNR [20dB], Validation Loss: 49.9821\n",
      "SNR [30dB], Validation Loss: 49.9665\n",
      "SNR [40dB], Validation Loss: 49.9635\n",
      "\n",
      "\n",
      "Epoch [16/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9635\n",
      "SNR [10dB], Validation Loss: 49.9534\n",
      "SNR [20dB], Validation Loss: 49.9823\n",
      "SNR [30dB], Validation Loss: 49.9667\n",
      "SNR [40dB], Validation Loss: 49.9633\n",
      "\n",
      "\n",
      "Epoch [17/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9634\n",
      "SNR [10dB], Validation Loss: 49.9531\n",
      "SNR [20dB], Validation Loss: 49.9821\n",
      "SNR [30dB], Validation Loss: 49.9666\n",
      "SNR [40dB], Validation Loss: 49.9633\n",
      "\n",
      "\n",
      "Epoch [18/50], Training Loss: 50.0027\n",
      "SNR [0dB], Validation Loss: 49.9634\n",
      "SNR [10dB], Validation Loss: 49.9536\n",
      "SNR [20dB], Validation Loss: 49.9823\n",
      "SNR [30dB], Validation Loss: 49.9666\n",
      "SNR [40dB], Validation Loss: 49.9633\n",
      "\n",
      "\n",
      "Epoch [19/50], Training Loss: 50.0027\n",
      "SNR [0dB], Validation Loss: 49.9636\n",
      "SNR [10dB], Validation Loss: 49.9534\n",
      "SNR [20dB], Validation Loss: 49.9822\n",
      "SNR [30dB], Validation Loss: 49.9665\n",
      "SNR [40dB], Validation Loss: 49.9631\n",
      "Epoch    19: reducing learning rate of group 0 to 1.2500e-06.\n",
      "\n",
      "\n",
      "Epoch [20/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9634\n",
      "SNR [10dB], Validation Loss: 49.9534\n",
      "SNR [20dB], Validation Loss: 49.9821\n",
      "SNR [30dB], Validation Loss: 49.9667\n",
      "SNR [40dB], Validation Loss: 49.9635\n",
      "\n",
      "\n",
      "Epoch [21/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9632\n",
      "SNR [10dB], Validation Loss: 49.9531\n",
      "SNR [20dB], Validation Loss: 49.9819\n",
      "SNR [30dB], Validation Loss: 49.9666\n",
      "SNR [40dB], Validation Loss: 49.9634\n",
      "\n",
      "\n",
      "Epoch [22/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9631\n",
      "SNR [10dB], Validation Loss: 49.9530\n",
      "SNR [20dB], Validation Loss: 49.9818\n",
      "SNR [30dB], Validation Loss: 49.9665\n",
      "SNR [40dB], Validation Loss: 49.9634\n",
      "\n",
      "\n",
      "Epoch [23/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9631\n",
      "SNR [10dB], Validation Loss: 49.9532\n",
      "SNR [20dB], Validation Loss: 49.9820\n",
      "SNR [30dB], Validation Loss: 49.9665\n",
      "SNR [40dB], Validation Loss: 49.9635\n",
      "\n",
      "\n",
      "Epoch [24/50], Training Loss: 50.0027\n",
      "SNR [0dB], Validation Loss: 49.9631\n",
      "SNR [10dB], Validation Loss: 49.9530\n",
      "SNR [20dB], Validation Loss: 49.9820\n",
      "SNR [30dB], Validation Loss: 49.9665\n",
      "SNR [40dB], Validation Loss: 49.9634\n",
      "\n",
      "\n",
      "Epoch [25/50], Training Loss: 50.0027\n",
      "SNR [0dB], Validation Loss: 49.9633\n",
      "SNR [10dB], Validation Loss: 49.9532\n",
      "SNR [20dB], Validation Loss: 49.9832\n",
      "SNR [30dB], Validation Loss: 49.9668\n",
      "SNR [40dB], Validation Loss: 49.9633\n",
      "Epoch    25: reducing learning rate of group 0 to 6.2500e-08.\n",
      "\n",
      "\n",
      "Epoch [26/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9636\n",
      "SNR [10dB], Validation Loss: 49.9536\n",
      "SNR [20dB], Validation Loss: 49.9834\n",
      "SNR [30dB], Validation Loss: 49.9664\n",
      "SNR [40dB], Validation Loss: 49.9632\n",
      "\n",
      "\n",
      "Epoch [27/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9632\n",
      "SNR [10dB], Validation Loss: 49.9536\n",
      "SNR [20dB], Validation Loss: 49.9824\n",
      "SNR [30dB], Validation Loss: 49.9666\n",
      "SNR [40dB], Validation Loss: 49.9636\n",
      "\n",
      "\n",
      "Epoch [28/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9635\n",
      "SNR [10dB], Validation Loss: 49.9535\n",
      "SNR [20dB], Validation Loss: 49.9822\n",
      "SNR [30dB], Validation Loss: 49.9667\n",
      "SNR [40dB], Validation Loss: 49.9632\n",
      "\n",
      "\n",
      "Epoch [29/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9635\n",
      "SNR [10dB], Validation Loss: 49.9537\n",
      "SNR [20dB], Validation Loss: 49.9833\n",
      "SNR [30dB], Validation Loss: 49.9669\n",
      "SNR [40dB], Validation Loss: 49.9631\n",
      "\n",
      "\n",
      "Epoch [30/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9635\n",
      "SNR [10dB], Validation Loss: 49.9536\n",
      "SNR [20dB], Validation Loss: 49.9833\n",
      "SNR [30dB], Validation Loss: 49.9668\n",
      "SNR [40dB], Validation Loss: 49.9630\n",
      "\n",
      "\n",
      "Epoch [31/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9634\n",
      "SNR [10dB], Validation Loss: 49.9536\n",
      "SNR [20dB], Validation Loss: 49.9833\n",
      "SNR [30dB], Validation Loss: 49.9669\n",
      "SNR [40dB], Validation Loss: 49.9632\n",
      "Epoch    31: reducing learning rate of group 0 to 3.1250e-09.\n",
      "\n",
      "\n",
      "Epoch [32/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9635\n",
      "SNR [10dB], Validation Loss: 49.9535\n",
      "SNR [20dB], Validation Loss: 49.9833\n",
      "SNR [30dB], Validation Loss: 49.9670\n",
      "SNR [40dB], Validation Loss: 49.9631\n",
      "\n",
      "\n",
      "Epoch [33/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9633\n",
      "SNR [10dB], Validation Loss: 49.9535\n",
      "SNR [20dB], Validation Loss: 49.9832\n",
      "SNR [30dB], Validation Loss: 49.9667\n",
      "SNR [40dB], Validation Loss: 49.9633\n",
      "\n",
      "\n",
      "Epoch [34/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9635\n",
      "SNR [10dB], Validation Loss: 49.9535\n",
      "SNR [20dB], Validation Loss: 49.9823\n",
      "SNR [30dB], Validation Loss: 49.9666\n",
      "SNR [40dB], Validation Loss: 49.9632\n",
      "\n",
      "\n",
      "Epoch [35/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9634\n",
      "SNR [10dB], Validation Loss: 49.9536\n",
      "SNR [20dB], Validation Loss: 49.9833\n",
      "SNR [30dB], Validation Loss: 49.9667\n",
      "SNR [40dB], Validation Loss: 49.9632\n",
      "\n",
      "\n",
      "Epoch [36/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9635\n",
      "SNR [10dB], Validation Loss: 49.9535\n",
      "SNR [20dB], Validation Loss: 49.9836\n",
      "SNR [30dB], Validation Loss: 49.9670\n",
      "SNR [40dB], Validation Loss: 49.9631\n",
      "\n",
      "\n",
      "Epoch [37/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9634\n",
      "SNR [10dB], Validation Loss: 49.9535\n",
      "SNR [20dB], Validation Loss: 49.9835\n",
      "SNR [30dB], Validation Loss: 49.9667\n",
      "SNR [40dB], Validation Loss: 49.9633\n",
      "\n",
      "\n",
      "Epoch [38/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9635\n",
      "SNR [10dB], Validation Loss: 49.9535\n",
      "SNR [20dB], Validation Loss: 49.9835\n",
      "SNR [30dB], Validation Loss: 49.9668\n",
      "SNR [40dB], Validation Loss: 49.9631\n",
      "\n",
      "\n",
      "Epoch [39/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9634\n",
      "SNR [10dB], Validation Loss: 49.9537\n",
      "SNR [20dB], Validation Loss: 49.9832\n",
      "SNR [30dB], Validation Loss: 49.9667\n",
      "SNR [40dB], Validation Loss: 49.9633\n",
      "\n",
      "\n",
      "Epoch [40/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9635\n",
      "SNR [10dB], Validation Loss: 49.9537\n",
      "SNR [20dB], Validation Loss: 49.9832\n",
      "SNR [30dB], Validation Loss: 49.9668\n",
      "SNR [40dB], Validation Loss: 49.9632\n",
      "\n",
      "\n",
      "Epoch [41/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9634\n",
      "SNR [10dB], Validation Loss: 49.9536\n",
      "SNR [20dB], Validation Loss: 49.9832\n",
      "SNR [30dB], Validation Loss: 49.9668\n",
      "SNR [40dB], Validation Loss: 49.9632\n",
      "\n",
      "\n",
      "Epoch [42/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9633\n",
      "SNR [10dB], Validation Loss: 49.9534\n",
      "SNR [20dB], Validation Loss: 49.9835\n",
      "SNR [30dB], Validation Loss: 49.9670\n",
      "SNR [40dB], Validation Loss: 49.9633\n",
      "\n",
      "\n",
      "Epoch [43/50], Training Loss: 50.0027\n",
      "SNR [0dB], Validation Loss: 49.9633\n",
      "SNR [10dB], Validation Loss: 49.9535\n",
      "SNR [20dB], Validation Loss: 49.9832\n",
      "SNR [30dB], Validation Loss: 49.9667\n",
      "SNR [40dB], Validation Loss: 49.9631\n",
      "\n",
      "\n",
      "Epoch [44/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9634\n",
      "SNR [10dB], Validation Loss: 49.9535\n",
      "SNR [20dB], Validation Loss: 49.9834\n",
      "SNR [30dB], Validation Loss: 49.9670\n",
      "SNR [40dB], Validation Loss: 49.9631\n",
      "\n",
      "\n",
      "Epoch [45/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9635\n",
      "SNR [10dB], Validation Loss: 49.9536\n",
      "SNR [20dB], Validation Loss: 49.9833\n",
      "SNR [30dB], Validation Loss: 49.9669\n",
      "SNR [40dB], Validation Loss: 49.9631\n",
      "\n",
      "\n",
      "Epoch [46/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9635\n",
      "SNR [10dB], Validation Loss: 49.9538\n",
      "SNR [20dB], Validation Loss: 49.9833\n",
      "SNR [30dB], Validation Loss: 49.9667\n",
      "SNR [40dB], Validation Loss: 49.9632\n",
      "\n",
      "\n",
      "Epoch [47/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9633\n",
      "SNR [10dB], Validation Loss: 49.9535\n",
      "SNR [20dB], Validation Loss: 49.9836\n",
      "SNR [30dB], Validation Loss: 49.9670\n",
      "SNR [40dB], Validation Loss: 49.9632\n",
      "\n",
      "\n",
      "Epoch [48/50], Training Loss: 50.0027\n",
      "SNR [0dB], Validation Loss: 49.9635\n",
      "SNR [10dB], Validation Loss: 49.9536\n",
      "SNR [20dB], Validation Loss: 49.9834\n",
      "SNR [30dB], Validation Loss: 49.9668\n",
      "SNR [40dB], Validation Loss: 49.9630\n",
      "\n",
      "\n",
      "Epoch [49/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9635\n",
      "SNR [10dB], Validation Loss: 49.9536\n",
      "SNR [20dB], Validation Loss: 49.9834\n",
      "SNR [30dB], Validation Loss: 49.9669\n",
      "SNR [40dB], Validation Loss: 49.9630\n",
      "\n",
      "\n",
      "Epoch [50/50], Training Loss: 50.0026\n",
      "SNR [0dB], Validation Loss: 49.9634\n",
      "SNR [10dB], Validation Loss: 49.9535\n",
      "SNR [20dB], Validation Loss: 49.9834\n",
      "SNR [30dB], Validation Loss: 49.9668\n",
      "SNR [40dB], Validation Loss: 49.9630\n",
      "\n",
      "\n",
      "Training Complete\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    print(\"Training Starts !!!!!!!\")\n",
    "    best_valid_loss = float('Inf')\n",
    "    for i in range(num_epochs):\n",
    "        training_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        epoch_loss = 0.0\n",
    "        training_mae = 0.0\n",
    "        classification_model.train()\n",
    "        for j,(features, labels) in enumerate(doa2_train_loader, 0):\n",
    "            features, labels = Variable(features.cuda()), Variable(labels.cuda())\n",
    "            optimizer.zero_grad()\n",
    "            enn = classification_model(features.float())\n",
    "            enn = F.sigmoid(enn)\n",
    "#             print(\"enn\", enn.size())\n",
    "#             print(\"features\", features.size())\n",
    "            losss = criterion(enn.cuda(), features.float())\n",
    "            losss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += losss.item()\n",
    "\n",
    "            epoch_loss += enn.shape[0] * losss.item()\n",
    "\n",
    "        loss_res['training'].append(training_loss/len(doa2_train_loader))\n",
    "        print('Epoch [{}/{}], Training Loss: {:.4f}'\n",
    "                      .format(i+1, num_epochs, training_loss/len(doa2_train_loader)))\n",
    "        \n",
    "        # Validation for each SNR value\n",
    "        classification_model.eval()\n",
    "        total_valdation_loss = 0\n",
    "        for val_data in range(0, len(test_dataset_list)):\n",
    "            \n",
    "            validation_loss = 0\n",
    "            validation_acc = 0\n",
    "            validation_mae = 0.0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for features, labels in test_dataset_list[val_data]:\n",
    "                    features, labels = Variable(features.cuda()), Variable(labels.cuda())\n",
    "                    enn = classification_model(features.float())\n",
    "                    enn = F.sigmoid(enn)\n",
    "#                     auto_outputs = torch.transpose(enn, 2, 3)\n",
    "#                     auto_outputs = torch.reshape(auto_outputs, (auto_outputs.shape[0], 181, 3))\n",
    "                    loss = criterion(enn.cuda(), features.float())\n",
    "\n",
    "#                     _, pred = torch.max(enn, 1)\n",
    "#                     val_total+= labels.reshape(-1).size(0)\n",
    "#                     val_correct+=(pred.reshape(-1).cuda() == labels.reshape(-1)).sum().item()\n",
    "                    validation_loss += loss.item()\n",
    "#                     validation_mae += torch.abs(pred.reshape(-1).cuda() - labels.reshape(-1)).sum().item()\n",
    "\n",
    "                loss_res[10*val_data].append(validation_loss/len(test_dataset_list[val_data]))\n",
    "                \n",
    "                print('SNR [{}dB], Validation Loss: {:.4f}'\n",
    "                      .format(val_data*10, validation_loss/len(test_dataset_list[val_data])))\n",
    "\n",
    "                total_valdation_loss+=validation_loss\n",
    "        scheduler.step(loss_res[\"training\"][len(loss_res[\"training\"])-1])\n",
    "        torch.save( classification_model, weights_dir+ \"/SNS_DOA_{}_Unet_model.pth\".format(doa))\n",
    "        if best_valid_loss > total_valdation_loss:\n",
    "            best_valid_loss = total_valdation_loss \n",
    "            # Saving Best Pre-Trained Model as .pth file\n",
    "            torch.save( classification_model, weights_dir+ \"/DOA_{}_best_Unet_model.pth\".format(doa))\n",
    "#         if i%10 == 0:\n",
    "#           ddf = pd.DataFrame(acc_res)\n",
    "#           ddf.to_csv(weights_dir+\"res_DOA_{}_model.csv\".format(doa))\n",
    "        print(\"\\n\")  \n",
    "\n",
    "train()\n",
    "print(\"Training Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "feae118f-4556-448e-8fe1-0d5368b0c1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ep = range(0, len(loss_res[\"training\"]))\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(ep, loss_res[\"training\"], label='Train')\n",
    "plt.plot(ep, loss_res[0], label='0 dB')\n",
    "plt.plot(ep, loss_res[10], label='10 dB')\n",
    "plt.plot(ep, loss_res[20], label='20 dB')\n",
    "plt.plot(ep, loss_res[30], label='30 dB')\n",
    "plt.plot(ep, loss_res[40], label='40 dB')\n",
    "plt.xlabel('Epochs', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "plt.title(\"DOA - {}\".format(doa))\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08bc68a-c7bd-4406-a670-f1a5b918f279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
