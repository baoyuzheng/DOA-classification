{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "510b858e-d3ee-4c49-9843-7c8a5b4bd917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np \n",
    "import math\n",
    "import pandas as pd\n",
    "import cmath\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np \n",
    "import math\n",
    "import pandas as pd\n",
    "import cmath\n",
    "\n",
    "#from unet import UNet\n",
    "# from auto import encoder, decoder\n",
    "\n",
    "from collections import OrderedDict\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "#==========================================================================\n",
    "# For Plotting loss graph\n",
    "# Bokeh\n",
    "from bokeh.io import curdoc\n",
    "from bokeh.layouts import column\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.plotting import figure\n",
    "\n",
    "from functools import partial\n",
    "from threading import Thread\n",
    "from tornado import gen\n",
    "# from AttRCNN_UNet import Att_R2U\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)\n",
    "import sys\n",
    "# from dataloader import norm\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sys import getsizeof\n",
    "# import wandb\n",
    "# import logging\n",
    "# logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cd238ad-b68f-47d7-9169-9dc488762097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=(3,3), stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=(3,3), stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=181):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=(1,3), stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=1)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=1)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=1)\n",
    "        self.linear = nn.Linear(25, num_classes)\n",
    "        self.adp_pool = nn.AdaptiveMaxPool2d((4, 25))\n",
    "        #self.flat = nn.Conv2d(in_channels=512, out_channels=1, kernel_size=1, stride=1)\n",
    "        self.flat = nn.Sequential(nn.Conv2d(in_channels=512, out_channels=1, kernel_size=1, stride=1))\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"Input ==> \", x.size())\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        # print(\"F.relu(self.bn1(self.conv1(x))) ==> \", x.size())\n",
    "        out = self.layer1(out)\n",
    "        # print(\"layer1 ==> \", x.size())\n",
    "        out = self.layer2(out)\n",
    "        # print(\"layer2 ==> \", x.size())\n",
    "        out = self.layer3(out)\n",
    "        # print(\"layer3 ==> \", x.size())\n",
    "        out = self.layer4(out)\n",
    "#         print(\"layer4 ==>\", out.size())\n",
    "#         out = self.adp_pool(out)\n",
    "        out = F.avg_pool2d(out, (3, 4))\n",
    "#         print(\"avg_pool2d ===>\", out.size())\n",
    "        # out = out.view(out.size(0), -1)\n",
    "        # print(\"out.view ===>\", out.size())\n",
    "        out = self.linear(out)\n",
    "        out = self.flat(out)\n",
    "#         print(\"Out ===>\", out.size())\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(BasicBlock, [3, 4, 23, 3])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image = torch.rand(1, 3, 10, 100)\n",
    "    model = ResNet34()\n",
    "    model(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e3964a-f9a7-4e7d-8bbf-c958587e9c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0848cf47-8e05-40be-854a-a9ce9b43f398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f25236a-eee4-4e3a-978c-e619803f71e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d2b5f3f-ea4d-4242-867a-0fba125c3972",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_list = []\n",
    "test_dataset_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13724f31-7e82-4be4-8a45-960289066d2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-767405c2f724>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf1\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../datasets/DOA4/SNR_NS_0_4_100000.mat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf2\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../datasets/DOA4/SNR_NS_10_4_100000.mat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf3\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../datasets/DOA4/SNR_NS_20_4_100000.mat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf4\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../datasets/DOA4/SNR_NS_30_4_100000.mat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf5\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../datasets/DOA4/SNR_NS_40_4_100000.mat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sio' is not defined"
     ]
    }
   ],
   "source": [
    "df1  = sio.loadmat(\"../datasets/DOA4/SNR_NS_0_4_100000.mat\")\n",
    "df2  = sio.loadmat(\"../datasets/DOA4/SNR_NS_10_4_100000.mat\")\n",
    "df3  = sio.loadmat(\"../datasets/DOA4/SNR_NS_20_4_100000.mat\")\n",
    "df4  = sio.loadmat(\"../datasets/DOA4/SNR_NS_30_4_100000.mat\")\n",
    "df5  = sio.loadmat(\"../datasets/DOA4/SNR_NS_40_4_100000.mat\")\n",
    "df = [df1, df2, df3, df4, df5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0c9ed61-a0ec-4c5d-b994-8efaa162d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_dataset_list = []\n",
    "new_test_dataset_list = []\n",
    "train_dataset_list_label = []\n",
    "test_dataset_list_label = []\n",
    "def create_dataset(df):\n",
    "    data = np.transpose(df['NS_data'], (2, 0, 1))\n",
    "    label = df['DOA']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.15, random_state=42)\n",
    "    new_train_dataset_list.extend(X_train)\n",
    "    new_test_dataset_list.append(X_test.tolist())\n",
    "    train_dataset_list_label.extend(y_train)\n",
    "    test_dataset_list_label.append(y_test.tolist())\n",
    "    \n",
    "for file in df:\n",
    "    create_dataset(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a67391b8-00eb-450a-b97b-f78c57f29c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df\n",
    "del df1\n",
    "del df2\n",
    "del df3\n",
    "del df4\n",
    "del df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f59f02e-2672-4863-b8ef-9e8acadc77cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, data in enumerate(new_train_dataset_list):\n",
    "    new = np.zeros((3, 8, 100))\n",
    "    for j in range(0, data.shape[0]):\n",
    "        for k in range(0, data.shape[1]):\n",
    "            new[0][j][k] = data[j][k].real\n",
    "            new[1][j][k] = data[j][k].imag\n",
    "            new[2][j][k] = cmath.phase(data[j][k])\n",
    "    new_train_dataset_list[idx] = new\n",
    "    \n",
    "for idx, data in enumerate(new_test_dataset_list):\n",
    "    for i, ndata in enumerate(data):\n",
    "        new = np.zeros((3, 8, 100))\n",
    "        for j in range(0, 8):\n",
    "            for k in range(0, 100):\n",
    "                new[0][j][k] = ndata[j][k].real\n",
    "                new[1][j][k] = ndata[j][k].imag\n",
    "                new[2][j][k] = cmath.phase(ndata[j][k])\n",
    "        new_test_dataset_list[idx][i] = new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cf4837a-9fbb-4344-b0a5-bb69472d6240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train, test, batch_size, train_bool=True):\n",
    "    class DOA_dataset(Dataset):\n",
    "        def __init__(self, train, test):\n",
    "            self.x = torch.from_numpy(np.array(train))\n",
    "            self.y = torch.from_numpy(np.asarray(test))\n",
    "            self.n_sample = len(self.y)\n",
    "        def __getitem__(self, index):\n",
    "            return self.x[index], self.y[index]\n",
    "        def __len__(self):\n",
    "            return self.n_sample\n",
    "\n",
    "    dataset = DOA_dataset(train, test)\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=train_bool)\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83ab9692-dba5-47de-b500-a04294b3f5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "doa2_train_loader = get_data(new_train_dataset_list, train_dataset_list_label, 64, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be5bac91-f4e3-4ed5-87e8-6f0efef1d88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del new_train_dataset_list\n",
    "del train_dataset_list_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c334ae01-01f1-4d01-ba0b-bec0fbe38c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "test_dataset_list = []\n",
    "for idx, data in enumerate(new_test_dataset_list):\n",
    "    print(type(data))\n",
    "    f = get_data(data, test_dataset_list_label[idx], 128, False)\n",
    "    test_dataset_list.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "167b216e-2d10-43af-88f9-2c8292602cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "del new_test_dataset_list\n",
    "del new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7b36c2c-f000-4bcc-bc8d-4b749721cb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_res = {\n",
    "    \"training\": [],\n",
    "    0: [],\n",
    "    10: [],\n",
    "    20: [],\n",
    "    30: [],\n",
    "    40: []\n",
    "}\n",
    "loss_res = {\n",
    "    \"training\": [],\n",
    "    0: [],\n",
    "    10: [],\n",
    "    20: [],\n",
    "    30: [],\n",
    "    40: []\n",
    "}\n",
    "mae_res = {\n",
    "    \"training\": [],\n",
    "    0: [],\n",
    "    10: [],\n",
    "    20: [],\n",
    "    30: [],\n",
    "    40: []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5105479e-6975-4e72-93f7-6228bbfdb015",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = \"doa_weights/NS/DOA_4_model.pth\"\n",
    "\n",
    "classification_model = torch.load(weights)\n",
    "# pre_model\n",
    "# for prams in classification_model.parameters():\n",
    "#       prams.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d45f3ba-888d-4313-ac72-1924ae75bc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "\tprint(torch.cuda.get_device_name(0))\n",
    "\tclassification_model = classification_model.cuda()\n",
    "\toptimizer = optim.AdamW(classification_model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "\tcriterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "171bba31-630e-46e4-880d-c095d5e25171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Starts !!!!!!!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 dim 1 must match mat2 dim 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-e3f4cbbb3ab1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m                   .format(val_data*10, validation_loss/len(test_dataset_list[val_data]), (100*(val_correct/val_total)), validation_mae/(128*len(test_dataset_list[val_data])*181)))\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Complete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-e3f4cbbb3ab1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataset_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0menn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                 \u001b[0mauto_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mauto_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauto_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mauto_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m181\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-a20c0c9705ff>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# out = out.view(out.size(0), -1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# print(\"out.view ===>\", out.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m#         print(\"Out ===>\", out.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1674\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1676\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1677\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1678\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 dim 1 must match mat2 dim 0"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    print(\"Training Starts !!!!!!!\")\n",
    "    # Validation for each SNR value\n",
    "    classification_model.eval()\n",
    "    total_valdation_loss = 0\n",
    "    for val_data in range(0, len(test_dataset_list)):\n",
    "\n",
    "        validation_loss = 0\n",
    "        validation_acc = 0\n",
    "        validation_mae = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for features, labels in test_dataset_list[val_data]:\n",
    "                features, labels = Variable(features.cuda()), Variable(labels.cuda())\n",
    "                enn = classification_model(features.float())\n",
    "                auto_outputs = torch.transpose(enn, 2, 3)\n",
    "                auto_outputs = torch.reshape(auto_outputs, (auto_outputs.shape[0], 181, 4))\n",
    "                loss = criterion(auto_outputs.cuda(), labels.type(torch.LongTensor).cuda())\n",
    "\n",
    "                _, pred = torch.max(auto_outputs, 1)\n",
    "                val_total+= labels.reshape(-1).size(0)\n",
    "                val_correct+=(pred.reshape(-1).cuda() == labels.reshape(-1)).sum().item()\n",
    "                validation_loss += loss.item()\n",
    "                validation_mae += torch.abs(pred.reshape(-1).cuda() - labels.reshape(-1)).sum().item()\n",
    "\n",
    "            loss_res[10*val_data].append(validation_loss/len(test_dataset_list[val_data]))\n",
    "            acc_res[10*val_data].append((100*(val_correct/val_total)))\n",
    "            mae_res[10*val_data].append(validation_mae/(128*len(test_dataset_list[val_data])*181))\n",
    "\n",
    "            print('SNR [{}dB], Validation Loss: {:.4f}, Validation Accuracy: {:.4f}, Validation MAE: {}'\n",
    "                  .format(val_data*10, validation_loss/len(test_dataset_list[val_data]), (100*(val_correct/val_total)), validation_mae/(128*len(test_dataset_list[val_data])*181)))\n",
    "\n",
    "train()\n",
    "print(\"Training Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c0f7c3-f5e2-4062-a96d-38c815e6aa0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6f288e-466a-4bc2-9d89-e2e12c09e6a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ae20ac-ec68-460e-a9d1-013313254321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6621428f-9390-44e5-a104-49f21ed8db5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b1ac43-aa78-4644-91dd-524a4cab1f17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45df6d25-2f2c-4489-977b-964d9316aeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preTrained =  ResNet34()\n",
    "# weights = \"doa_weights/NS/DOA_4_best_model.pth\"\n",
    "\n",
    "# pre_model = torch.load(weights)\n",
    "\n",
    "# preTrained.load_state_dict(pre_model, strict=False)\n",
    "\n",
    "# for prams in preTrained.parameters():\n",
    "#       prams.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67442b7d-576c-4117-9892-88e86560bb3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d716ebe-8e76-4848-8c69-3bf2e8948e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcf70749-cc6d-48d4-bd16-66fd4c7e84ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet34 import ResNet34, ResNet18, ResNet101\n",
    "# from resnext import Inceptionv4\n",
    "res_model = ResNet34()\n",
    "# model = res_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "808bba91-3ab7-4e78-8546-550905170a88",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b1c5bbe3dd13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    image = torch.rand(1, 3, 8, 100)\n",
    "    model = res_model()\n",
    "    print(model(image).size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9ba9c1e-bfd0-4c77-9a63-a566c51ddc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7668637c-540e-4cc9-a197-bb44d77e1836",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save( model, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186f0ec5-ac09-4099-b440-6c93017fbfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "total_valdation_loss = 0\n",
    "for val_data in range(0, len(test_dataset_list)):\n",
    "    \n",
    "    validation_loss = 0\n",
    "    validation_acc = 0\n",
    "    validation_mae = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_dataset_list[val_data]:\n",
    "            features, labels = Variable(features.cuda()), Variable(labels.cuda())\n",
    "            enn = classification_model(features.float())\n",
    "            auto_outputs = torch.transpose(enn, 2, 3)\n",
    "            auto_outputs = torch.reshape(auto_outputs, (auto_outputs.shape[0], 181, 1))\n",
    "            loss = criterion(auto_outputs.cuda(), labels.type(torch.LongTensor).cuda())\n",
    "\n",
    "            _, pred = torch.max(auto_outputs, 1)\n",
    "            val_total+= labels.reshape(-1).size(0)\n",
    "            # print(\"######### pred ###########\")\n",
    "            # print(pred[0])\n",
    "            # print(\"######### label ###########\")\n",
    "            # print(labels[0])\n",
    "            val_correct+=(pred.reshape(-1).cuda() == labels.reshape(-1)).sum().item()\n",
    "            validation_loss += loss.item()\n",
    "            validation_mae += torch.abs(pred.reshape(-1).cuda() - labels.reshape(-1)).sum().item()\n",
    "\n",
    "        loss_res[10*val_data].append(validation_loss/len(test_dataset_list[val_data]))\n",
    "        acc_res[10*val_data].append((100*(val_correct/val_total)))\n",
    "    print(val_correct, val_total)\n",
    "    print(val_data*10, \"dB SNR is validated\")\n",
    "    print('SNR [{}dB], Validation Loss: {:.4f}, Validation Accuracy: {:.4f}'\n",
    "              .format(val_data*10, validation_loss/len(doa2_train_loader), (100*(val_correct/val_total))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
