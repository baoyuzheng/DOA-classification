{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DOA6.ipynb","provenance":[],"machine_shape":"hm","mount_file_id":"1PiA1qYx4SeEUe3_E4SD-DuODnXRA4k5y","authorship_tag":"ABX9TyPhcJP658/Ld8mPjppOtu2U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ESWhxMrz4esE","executionInfo":{"status":"ok","timestamp":1623513580584,"user_tz":-330,"elapsed":3396,"user":{"displayName":"Mohammad Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1sqT9k-ZJhDQXM7x7dup6__HgCR7MEKRseC9t6w=s64","userId":"07657306696827110934"}},"outputId":"aff56464-567c-475d-b3a5-e876130d1cde","colab":{"base_uri":"https://localhost:8080/"}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=(3,3), stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=(3,3), stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.relu1 = nn.ReLU(inplace=True)\n","        self.relu2 = nn.ReLU(inplace=True)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu1(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out += self.shortcut(x)\n","        out = self.relu2(out)\n","        return out\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=181):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=(1,3), stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=1)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=1)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=1)\n","        self.linear = nn.Linear(100, num_classes)\n","        self.adp_pool = nn.AdaptiveMaxPool2d((6, 100))\n","        #self.flat = nn.Conv2d(in_channels=512, out_channels=1, kernel_size=1, stride=1)\n","        self.flat = nn.Conv2d(in_channels=512, out_channels=1, kernel_size=1, stride=1)\n","        self.dropout = nn.Dropout(0.4)\n","        self.dropout1 = nn.Dropout(0.3)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        # print(\"Input ==> \", x.size())\n","        out = self.relu(self.bn1(self.conv1(x)))\n","        # print(\"F.relu(self.bn1(self.conv1(x))) ==> \", x.size())\n","        out = self.layer1(out)\n","        # print(\"layer1 ==> \", x.size())\n","        out = self.layer2(out)\n","        # print(\"layer2 ==> \", x.size())\n","        out = self.layer3(out)\n","        # print(\"layer3 ==> \", x.size())\n","        out = self.dropout(out)\n","        out = self.layer4(out)\n","        out = self.dropout1(out)\n","#         print(\"layer4 ==>\", out.size())\n","        out = self.adp_pool(out)\n","        \n","#         print(\"avg_pool2d ===>\", out.size())\n","        # out = out.view(out.size(0), -1)\n","        # print(\"out.view ===>\", out.size())\n","        out = self.linear(out)\n","        out = self.dropout(out)\n","        out = self.flat(out)\n","#         print(\"Out ===>\", out.size())\n","        return out\n","\n","\n","def ResNet18():\n","    return ResNet(BasicBlock, [2, 2, 2, 2])\n","\n","\n","def ResNet34():\n","    return ResNet(BasicBlock, [2, 3, 5, 2])\n","\n","def ResNet101():\n","    return ResNet(BasicBlock, [3, 4, 23, 3])\n","\n","\n","if __name__ == \"__main__\":\n","    image = torch.rand(1, 3, 10, 100)\n","    model = ResNet34()\n","    print(model(image).size())\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["torch.Size([1, 1, 6, 181])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FWK8PJ-r6P_H","executionInfo":{"status":"ok","timestamp":1623513581318,"user_tz":-330,"elapsed":744,"user":{"displayName":"Mohammad Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1sqT9k-ZJhDQXM7x7dup6__HgCR7MEKRseC9t6w=s64","userId":"07657306696827110934"}}},"source":["import scipy.io as sio\n","import numpy as np\n","import torch\n","from torch import nn, optim\n","import torchvision\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import numpy as np \n","import math\n","import pandas as pd\n","import cmath\n","import scipy.io as sio\n","import numpy as np\n","import torch\n","from torch import nn, optim\n","import torchvision\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np \n","import math\n","import pandas as pd\n","import cmath\n","import os\n","from os import listdir\n","from os.path import isfile, join\n","#from unet import UNet\n","# from auto import encoder, decoder\n","\n","from collections import OrderedDict\n","from torch.utils.data.sampler import SubsetRandomSampler\n","from torch.autograd import Variable\n","#==========================================================================\n","# For Plotting loss graph\n","# Bokeh\n","from bokeh.io import curdoc\n","from bokeh.layouts import column\n","from bokeh.models import ColumnDataSource\n","from bokeh.plotting import figure\n","\n","from functools import partial\n","from threading import Thread\n","from tornado import gen\n","# from AttRCNN_UNet import Att_R2U\n","import logging\n","logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)\n","import sys\n","# from dataloader import norm\n","\n","# import wandb\n","# import logging\n","# logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"mi4dAV736fo6","executionInfo":{"status":"ok","timestamp":1623513581320,"user_tz":-330,"elapsed":20,"user":{"displayName":"Mohammad Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1sqT9k-ZJhDQXM7x7dup6__HgCR7MEKRseC9t6w=s64","userId":"07657306696827110934"}}},"source":["train_dataset_list = []\n","test_dataset_list = []"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"3w1wuLwM6iVd","executionInfo":{"status":"ok","timestamp":1623513581782,"user_tz":-330,"elapsed":479,"user":{"displayName":"Mohammad Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1sqT9k-ZJhDQXM7x7dup6__HgCR7MEKRseC9t6w=s64","userId":"07657306696827110934"}}},"source":["import csv\n","from sklearn.model_selection import train_test_split\n","from sys import getsizeof"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"N6oywOMW6kvm","executionInfo":{"status":"error","timestamp":1623513581784,"user_tz":-330,"elapsed":11,"user":{"displayName":"Mohammad Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1sqT9k-ZJhDQXM7x7dup6__HgCR7MEKRseC9t6w=s64","userId":"07657306696827110934"}},"outputId":"eff9c300-7154-4dd7-84b7-23278aac8c30","colab":{"base_uri":"https://localhost:8080/","height":434}},"source":["df1  = sio.loadmat(\"/content/drive/MyDrive/DOA/DOA6/SNR_NS_0_6_100000.mat\")\n","df2  = sio.loadmat(\"/content/drive/MyDrive/DOA/DOA6/SNR_NS_10_6_100000.mat\")\n","df3  = sio.loadmat(\"/content/drive/MyDrive/DOA/DOA6/SNR_NS_20_6_100000.mat\")\n","df4  = sio.loadmat(\"/content/drive/MyDrive/DOA/DOA6/SNR_NS_30_6_100000.mat\")\n","df5  = sio.loadmat(\"/content/drive/MyDrive/DOA/DOA6/SNR_NS_40_6_100000.mat\")"],"execution_count":5,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/DOA/DOA6/SNR_NS_0_6_100000.mat'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-498a0ce62306>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf1\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/DOA/DOA6/SNR_NS_0_6_100000.mat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf2\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/DOA/DOA6/SNR_NS_10_6_100000.mat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf3\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/DOA/DOA6/SNR_NS_20_6_100000.mat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf4\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/DOA/DOA6/SNR_NS_30_6_100000.mat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf5\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/DOA/DOA6/SNR_NS_40_6_100000.mat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \"\"\"\n\u001b[1;32m    215\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reader needs file name or open file-like object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/DOA/DOA6/SNR_NS_0_6_100000.mat'"]}]},{"cell_type":"code","metadata":{"id":"BC0m0Z9N8yTv"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"59NkMdDQ6r1H","executionInfo":{"status":"aborted","timestamp":1623513581783,"user_tz":-330,"elapsed":7,"user":{"displayName":"Mohammad Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1sqT9k-ZJhDQXM7x7dup6__HgCR7MEKRseC9t6w=s64","userId":"07657306696827110934"}}},"source":["df = [df1, df2, df3, df4, df5]\n","# a = getsizeof(df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QTqEWGtf6uSA"},"source":["new_train_dataset_list = []\n","new_test_dataset_list = []\n","train_dataset_list_label = []\n","test_dataset_list_label = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k099OqsP6v7p"},"source":["def create_dataset(df):\n","    data = np.transpose(df['NS_data'], (2, 0, 1))\n","    label = df['DOA']\n","    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.15, random_state=42)\n","    new_train_dataset_list.extend(X_train)\n","    new_test_dataset_list.append(X_test.tolist())\n","    train_dataset_list_label.extend(y_train)\n","    test_dataset_list_label.append(y_test.tolist())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ETY1ZKTq6xoX"},"source":["for file in df:\n","    create_dataset(file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YdI8AeSJ6zov"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R0az4oy661jp"},"source":["del df\n","del df1\n","del df2\n","del df3\n","del df4\n","del df5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XNUH9tNY61s2","executionInfo":{"status":"ok","timestamp":1620633599954,"user_tz":-330,"elapsed":99258,"user":{"displayName":"Mohammad Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1sqT9k-ZJhDQXM7x7dup6__HgCR7MEKRseC9t6w=s64","userId":"07657306696827110934"}},"outputId":"16a999a1-1c90-4963-c761-9ccaaed9eeb6"},"source":["len(test_dataset_list_label[0])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15000"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"VuIhFX-I61w1"},"source":["for idx, data in enumerate(new_train_dataset_list):\n","    new = np.zeros((3, 8, 100))\n","    for j in range(0, data.shape[0]):\n","        for k in range(0, data.shape[1]):\n","            new[0][j][k] = data[j][k].real\n","            new[1][j][k] = data[j][k].imag\n","            new[2][j][k] = cmath.phase(data[j][k])\n","    new_train_dataset_list[idx] = new"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dwCFkXqS66KN"},"source":["for idx, data in enumerate(new_test_dataset_list):\n","    for i, ndata in enumerate(data):\n","        new = np.zeros((3, 8, 100))\n","        for j in range(0, 8):\n","            for k in range(0, 100):\n","                new[0][j][k] = ndata[j][k].real\n","                new[1][j][k] = ndata[j][k].imag\n","                new[2][j][k] = cmath.phase(ndata[j][k])\n","        new_test_dataset_list[idx][i] = new"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dnw0pbcz673A"},"source":["def get_data(train, test, batch_size, train_bool=True):\n","    class DOA_dataset(Dataset):\n","        def __init__(self, train, test):\n","            self.x = torch.from_numpy(np.array(train))\n","            self.y = torch.from_numpy(np.asarray(test))\n","            self.n_sample = len(self.y)\n","        def __getitem__(self, index):\n","            return self.x[index], self.y[index]\n","        def __len__(self):\n","            return self.n_sample\n","\n","\n","    dataset = DOA_dataset(train, test)\n","    \n","\n","    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=train_bool)\n","    return loader\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ry7WAADJ6_Eg"},"source":["doa2_train_loader = get_data(new_train_dataset_list, train_dataset_list_label, 64, True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ETJnqt1L7BB7"},"source":["del new_train_dataset_list\n","del train_dataset_list_label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hgbZJfIY7CnH"},"source":["test_dataset_list = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OCOsGnPL7Eiy","executionInfo":{"status":"ok","timestamp":1620634982298,"user_tz":-330,"elapsed":1479427,"user":{"displayName":"Mohammad Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1sqT9k-ZJhDQXM7x7dup6__HgCR7MEKRseC9t6w=s64","userId":"07657306696827110934"}},"outputId":"a12278d1-de77-4deb-d6e5-d141ccbc70de"},"source":["for idx, data in enumerate(new_test_dataset_list):\n","    print(type(data))\n","    f = get_data(data, test_dataset_list_label[idx], 128, False)\n","    test_dataset_list.append(f)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'list'>\n","<class 'list'>\n","<class 'list'>\n","<class 'list'>\n","<class 'list'>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KsDdQzC17GNw"},"source":["del new_test_dataset_list\n","del new"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Ml3H_YJ7Kbw","executionInfo":{"status":"ok","timestamp":1620634984540,"user_tz":-330,"elapsed":1479784,"user":{"displayName":"Mohammad Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1sqT9k-ZJhDQXM7x7dup6__HgCR7MEKRseC9t6w=s64","userId":"07657306696827110934"}},"outputId":"3eb71467-97f2-4627-a041-c1f4e82fd8ab"},"source":["num_epochs = 50\n","doa = 6\n","weights_dir = \"/content/drive/MyDrive/DOA/doa_weights/\"\n","\n","autoencoder = ResNet34()\n","criterion = nn.CrossEntropyLoss()\n","if ('DOA_{}_model.pth'.format(doa) in [f for f in listdir(weights_dir) if isfile(join(weights_dir, f))]):\n","    print(\"Pre-trained available for DOA_{}_model.pth\".format(doa))\n","    autoencoder = torch.load(os.path.join(weights_dir, 'DOA_{}_model.pth'.format(doa)))\n","if torch.cuda.is_available():\n","\tprint(torch.cuda.get_device_name(0))\n","\tclassification_model = autoencoder.cuda()\n","\toptimizer = optim.AdamW(classification_model.parameters(), lr=0.001, weight_decay=1e-5)\n","\tcriterion = criterion.cuda()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Pre-trained available for DOA_6_model.pth\n","Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uLiLzXyd7OKW"},"source":["acc_res = {\n","    \"training\": [],\n","    0: [],\n","    10: [],\n","    20: [],\n","    30: [],\n","    40: []\n","}\n","loss_res = {\n","    \"training\": [],\n","    0: [],\n","    10: [],\n","    20: [],\n","    30: [],\n","    40: []\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v7rWUsrfSPH8","outputId":"76073d75-7ed3-4968-de6e-7a35b4f0c660"},"source":["def train():\n","    print(\"Training Starts !!!!!!!\")\n","    \n","    best_valid_loss = float('Inf')\n","    for i in range(num_epochs):\n","        training_loss = 0\n","        train_correct = 0\n","        train_total = 0\n","        epoch_loss = 0.0\n","        training_mae = 0.0\n","        classification_model.train()\n","        for j,(features, labels) in enumerate(doa2_train_loader, 0):\n","            features, labels = Variable(features.cuda()), Variable(labels.cuda())\n","            optimizer.zero_grad()\n","            enn = classification_model(features.float())\n","            auto_outputs = torch.transpose(enn, 2, 3)\n","            auto_outputs = torch.reshape(auto_outputs.cuda(), (auto_outputs.shape[0], 181, 6))\n","            losss = criterion(auto_outputs.cuda(), labels.type(torch.LongTensor).cuda())\n","            losss.backward()\n","            optimizer.step()\n","#           exp_scheduler.step()\n","            training_loss += losss.item()\n","\n","            _, pred = torch.max(auto_outputs, 1)\n","\n","            train_total+= labels.reshape(-1).size(0)\n","\n","            train_correct+=(pred.reshape(-1).cuda() == labels.reshape(-1)).sum().item()\n","\n","            epoch_loss += auto_outputs.shape[0] * losss.item()\n","            training_mae += torch.abs(pred.reshape(-1).cuda() - labels.reshape(-1)).sum().item()  \n","\n","        loss_res['training'].append(training_loss/len(doa2_train_loader))\n","        acc_res['training'].append((100*(train_correct/train_total)))\n","\n","        print('Epoch [{}/{}], Training Loss: {:.4f}, Training Accuracy: {:.4f}'\n","                      .format(i+1, num_epochs, training_loss/len(doa2_train_loader), (100*(train_correct/train_total))))\n","        \n","        # Validation for each SNR value\n","        classification_model.eval()\n","        total_valdation_loss = 0\n","        for val_data in range(0, len(test_dataset_list)):\n","            \n","            validation_loss = 0\n","            validation_acc = 0\n","            validation_mae = 0.0\n","            val_correct = 0\n","            val_total = 0\n","\n","            with torch.no_grad():\n","                for features, labels in test_dataset_list[val_data]:\n","                    features, labels = Variable(features.cuda()), Variable(labels.cuda())\n","                    enn = classification_model(features.float())\n","                    auto_outputs = torch.transpose(enn, 2, 3)\n","                    auto_outputs = torch.reshape(auto_outputs, (auto_outputs.shape[0], 181, 6))\n","                    loss = criterion(auto_outputs.cuda(), labels.type(torch.LongTensor).cuda())\n","\n","                    _, pred = torch.max(auto_outputs, 1)\n","                    val_total+= labels.reshape(-1).size(0)\n","                    val_correct+=(pred.reshape(-1).cuda() == labels.reshape(-1)).sum().item()\n","                    validation_loss += loss.item()\n","                    validation_mae += torch.abs(pred.reshape(-1).cuda() - labels.reshape(-1)).sum().item()\n","                # print(val_correct, val_total)\n","                loss_res[10*val_data].append(validation_loss/len(test_dataset_list[val_data]))\n","                acc_res[10*val_data].append((100*(val_correct/val_total)))\n","\n","                # print(val_data*10, \"dB SNR is validated\")\n","                print('SNR [{}d], Validation Loss: {:.4f}, Validation Accuracy: {:.4f}'\n","                          .format(val_data*10, validation_loss/len(test_dataset_list[val_data]), (100*(val_correct/val_total))))\n","\n","            total_valdation_loss+=validation_loss\n","\n","            if best_valid_loss > total_valdation_loss:\n","                best_valid_loss = total_valdation_loss \n","                # Saving Best Pre-Trained Model as .pth file\n","                torch.save( model, \"/content/drive/MyDrive/DOA/doa_weights/DOA_{}_model.pth\".format(doa))\n","        if i%10 == 0:\n","          ddf = pd.DataFrame(acc_res)\n","          ddf.to_csv(\"/content/drive/MyDrive/DOA/doa_weights/res_DOA_{}_model.csv\".format(doa))\n","        print(\"\\n\")  \n","\n","train()\n","print(\"Training Complete\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training Starts !!!!!!!\n","Epoch [1/50], Training Loss: 4.4952, Training Accuracy: 2.9153\n","SNR [0d], Validation Loss: 4.1279, Validation Accuracy: 4.5011\n","SNR [10d], Validation Loss: 3.6522, Validation Accuracy: 6.6644\n","SNR [20d], Validation Loss: 3.5588, Validation Accuracy: 7.1322\n","SNR [30d], Validation Loss: 3.5454, Validation Accuracy: 7.2256\n","SNR [40d], Validation Loss: 3.5453, Validation Accuracy: 7.3167\n","\n","\n","Epoch [2/50], Training Loss: 3.2179, Training Accuracy: 10.1779\n","SNR [0d], Validation Loss: 3.5459, Validation Accuracy: 8.5022\n","SNR [10d], Validation Loss: 2.9353, Validation Accuracy: 13.2433\n","SNR [20d], Validation Loss: 2.8294, Validation Accuracy: 14.3600\n","SNR [30d], Validation Loss: 2.8183, Validation Accuracy: 14.6322\n","SNR [40d], Validation Loss: 2.8144, Validation Accuracy: 14.5700\n","\n","\n","Epoch [3/50], Training Loss: 2.6390, Training Accuracy: 17.0187\n","SNR [0d], Validation Loss: 3.1544, Validation Accuracy: 11.8389\n","SNR [10d], Validation Loss: 2.4584, Validation Accuracy: 19.6456\n","SNR [20d], Validation Loss: 2.3044, Validation Accuracy: 21.5944\n","SNR [30d], Validation Loss: 2.2818, Validation Accuracy: 21.9356\n","SNR [40d], Validation Loss: 2.2798, Validation Accuracy: 22.2044\n","\n","\n","Epoch [4/50], Training Loss: 2.3170, Training Accuracy: 22.7773\n","SNR [0d], Validation Loss: 2.9510, Validation Accuracy: 14.4633\n","SNR [10d], Validation Loss: 2.2474, Validation Accuracy: 23.6089\n","SNR [20d], Validation Loss: 2.0795, Validation Accuracy: 26.8944\n","SNR [30d], Validation Loss: 2.0528, Validation Accuracy: 27.2722\n","SNR [40d], Validation Loss: 2.0516, Validation Accuracy: 27.1089\n","\n","\n","Epoch [5/50], Training Loss: 2.1219, Training Accuracy: 27.0335\n","SNR [0d], Validation Loss: 2.8233, Validation Accuracy: 16.5411\n","SNR [10d], Validation Loss: 2.0355, Validation Accuracy: 28.9756\n","SNR [20d], Validation Loss: 1.8340, Validation Accuracy: 33.2367\n","SNR [30d], Validation Loss: 1.8002, Validation Accuracy: 34.0456\n","SNR [40d], Validation Loss: 1.7950, Validation Accuracy: 34.2933\n","\n","\n","Epoch [6/50], Training Loss: 1.9788, Training Accuracy: 30.6049\n","SNR [0d], Validation Loss: 2.7664, Validation Accuracy: 17.3133\n","SNR [10d], Validation Loss: 1.9314, Validation Accuracy: 32.0400\n","SNR [20d], Validation Loss: 1.7139, Validation Accuracy: 37.4133\n","SNR [30d], Validation Loss: 1.6659, Validation Accuracy: 38.7489\n","SNR [40d], Validation Loss: 1.6652, Validation Accuracy: 38.3389\n","\n","\n","Epoch [7/50], Training Loss: 1.8670, Training Accuracy: 33.6456\n","SNR [0d], Validation Loss: 2.7114, Validation Accuracy: 17.9078\n","SNR [10d], Validation Loss: 1.8532, Validation Accuracy: 33.7478\n","SNR [20d], Validation Loss: 1.5995, Validation Accuracy: 40.3878\n","SNR [30d], Validation Loss: 1.5583, Validation Accuracy: 41.4067\n","SNR [40d], Validation Loss: 1.5531, Validation Accuracy: 41.6400\n","\n","\n","Epoch [8/50], Training Loss: 1.7784, Training Accuracy: 36.2675\n","SNR [0d], Validation Loss: 2.7161, Validation Accuracy: 18.2289\n","SNR [10d], Validation Loss: 1.9139, Validation Accuracy: 32.6356\n","SNR [20d], Validation Loss: 1.7036, Validation Accuracy: 37.9256\n","SNR [30d], Validation Loss: 1.6575, Validation Accuracy: 39.2567\n","SNR [40d], Validation Loss: 1.6640, Validation Accuracy: 39.0489\n","\n","\n","Epoch [9/50], Training Loss: 1.7033, Training Accuracy: 38.5661\n","SNR [0d], Validation Loss: 2.6698, Validation Accuracy: 18.9656\n","SNR [10d], Validation Loss: 1.7721, Validation Accuracy: 36.2922\n","SNR [20d], Validation Loss: 1.4730, Validation Accuracy: 44.0367\n","SNR [30d], Validation Loss: 1.4222, Validation Accuracy: 45.4889\n","SNR [40d], Validation Loss: 1.4165, Validation Accuracy: 45.6911\n","\n","\n","Epoch [10/50], Training Loss: 1.6379, Training Accuracy: 40.5802\n","SNR [0d], Validation Loss: 2.6419, Validation Accuracy: 19.3544\n","SNR [10d], Validation Loss: 1.7349, Validation Accuracy: 37.4822\n","SNR [20d], Validation Loss: 1.4283, Validation Accuracy: 46.1489\n","SNR [30d], Validation Loss: 1.3787, Validation Accuracy: 47.6444\n","SNR [40d], Validation Loss: 1.3692, Validation Accuracy: 47.7900\n","\n","\n","Epoch [11/50], Training Loss: 1.5868, Training Accuracy: 42.1972\n","SNR [0d], Validation Loss: 2.6252, Validation Accuracy: 19.8611\n","SNR [10d], Validation Loss: 1.6884, Validation Accuracy: 38.9367\n","SNR [20d], Validation Loss: 1.3511, Validation Accuracy: 48.3500\n","SNR [30d], Validation Loss: 1.2892, Validation Accuracy: 50.4033\n","SNR [40d], Validation Loss: 1.2835, Validation Accuracy: 50.5856\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qtTFy7cH7Qaj","outputId":"2c181469-be82-4553-ea92-ef70b70e1c41"},"source":["def train():\n","    print(\"Training Starts !!!!!!!\")\n","    \n","    best_valid_loss = float('Inf')\n","    for i in range(num_epochs):\n","        training_loss = 0\n","        train_correct = 0\n","        train_total = 0\n","        epoch_loss = 0.0\n","        training_mae = 0.0\n","        classification_model.train()\n","        for j,(features, labels) in enumerate(doa2_train_loader, 0):\n","            features, labels = Variable(features.cuda()), Variable(labels.cuda())\n","            optimizer.zero_grad()\n","            enn = classification_model(features.float())\n","            auto_outputs = torch.transpose(enn, 2, 3)\n","            auto_outputs = torch.reshape(auto_outputs.cuda(), (auto_outputs.shape[0], 181, 6))\n","            losss = criterion(auto_outputs.cuda(), labels.type(torch.LongTensor).cuda())\n","            losss.backward()\n","            optimizer.step()\n","#           exp_scheduler.step()\n","            training_loss += losss.item()\n","\n","            _, pred = torch.max(auto_outputs, 1)\n","\n","            train_total+= labels.reshape(-1).size(0)\n","\n","            train_correct+=(pred.reshape(-1).cuda() == labels.reshape(-1)).sum().item()\n","\n","            epoch_loss += auto_outputs.shape[0] * losss.item()\n","            training_mae += torch.abs(pred.reshape(-1).cuda() - labels.reshape(-1)).sum().item()  \n","\n","        loss_res['training'].append(training_loss/len(doa2_train_loader))\n","        acc_res['training'].append((100*(train_correct/train_total)))\n","\n","        print('Epoch [{}/{}], Training Loss: {:.4f}, Training Accuracy: {:.4f}'\n","                      .format(i+1, num_epochs, training_loss/len(doa2_train_loader), (100*(train_correct/train_total))))\n","        \n","        # Validation for each SNR value\n","        classification_model.eval()\n","        total_valdation_loss = 0\n","        for val_data in range(0, len(test_dataset_list)):\n","            \n","            validation_loss = 0\n","            validation_acc = 0\n","            validation_mae = 0.0\n","            val_correct = 0\n","            val_total = 0\n","\n","            with torch.no_grad():\n","                for features, labels in test_dataset_list[val_data]:\n","                    features, labels = Variable(features.cuda()), Variable(labels.cuda())\n","                    enn = classification_model(features.float())\n","                    auto_outputs = torch.transpose(enn, 2, 3)\n","                    auto_outputs = torch.reshape(auto_outputs, (auto_outputs.shape[0], 181, 6))\n","                    loss = criterion(auto_outputs.cuda(), labels.type(torch.LongTensor).cuda())\n","\n","                    _, pred = torch.max(auto_outputs, 1)\n","                    val_total+= labels.reshape(-1).size(0)\n","                    val_correct+=(pred.reshape(-1).cuda() == labels.reshape(-1)).sum().item()\n","                    validation_loss += loss.item()\n","                    validation_mae += torch.abs(pred.reshape(-1).cuda() - labels.reshape(-1)).sum().item()\n","                # print(val_correct, val_total)\n","                loss_res[10*val_data].append(validation_loss/len(test_dataset_list[val_data]))\n","                acc_res[10*val_data].append((100*(val_correct/val_total)))\n","\n","                # print(val_data*10, \"dB SNR is validated\")\n","                print('SNR [{}d], Validation Loss: {:.4f}, Validation Accuracy: {:.4f}'\n","                          .format(val_data*10, validation_loss/len(test_dataset_list[val_data]), (100*(val_correct/val_total))))\n","\n","            total_valdation_loss+=validation_loss\n","\n","            if best_valid_loss > total_valdation_loss:\n","                best_valid_loss = total_valdation_loss \n","                # Saving Best Pre-Trained Model as .pth file\n","                torch.save( model, \"/content/drive/MyDrive/DOA/doa_weights/DOA_{}_model.pth\".format(doa))\n","        if i%10 == 0:\n","          ddf = pd.DataFrame(acc_res)\n","          ddf.to_csv(\"/content/drive/MyDrive/DOA/doa_weights/res_DOA_{}_model.csv\".format(doa))\n","        print(\"\\n\")  \n","\n","train()\n","print(\"Training Complete\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training Starts !!!!!!!\n","Epoch [1/50], Training Loss: 4.5150, Training Accuracy: 2.8735\n","SNR [0d], Validation Loss: 4.2476, Validation Accuracy: 4.1622\n","SNR [10d], Validation Loss: 3.7645, Validation Accuracy: 6.3833\n","SNR [20d], Validation Loss: 3.6736, Validation Accuracy: 6.9744\n","SNR [30d], Validation Loss: 3.6611, Validation Accuracy: 6.8400\n","SNR [40d], Validation Loss: 3.6566, Validation Accuracy: 7.0311\n","\n","\n","Epoch [2/50], Training Loss: 3.1240, Training Accuracy: 11.6122\n","SNR [0d], Validation Loss: 3.4087, Validation Accuracy: 9.6633\n","SNR [10d], Validation Loss: 2.7039, Validation Accuracy: 16.0256\n","SNR [20d], Validation Loss: 2.5447, Validation Accuracy: 17.7444\n","SNR [30d], Validation Loss: 2.5273, Validation Accuracy: 17.9367\n","SNR [40d], Validation Loss: 2.5209, Validation Accuracy: 17.9467\n","\n","\n","Epoch [3/50], Training Loss: 2.5547, Training Accuracy: 18.9391\n","SNR [0d], Validation Loss: 3.2238, Validation Accuracy: 11.8100\n","SNR [10d], Validation Loss: 2.4770, Validation Accuracy: 20.1467\n","SNR [20d], Validation Loss: 2.3063, Validation Accuracy: 22.2056\n","SNR [30d], Validation Loss: 2.2873, Validation Accuracy: 22.7989\n","SNR [40d], Validation Loss: 2.2759, Validation Accuracy: 22.8022\n","\n","\n","Epoch [4/50], Training Loss: 2.2939, Training Accuracy: 23.7624\n","SNR [0d], Validation Loss: 3.0325, Validation Accuracy: 13.9500\n","SNR [10d], Validation Loss: 2.2459, Validation Accuracy: 24.7611\n","SNR [20d], Validation Loss: 2.0249, Validation Accuracy: 28.7933\n","SNR [30d], Validation Loss: 1.9900, Validation Accuracy: 29.8011\n","SNR [40d], Validation Loss: 1.9837, Validation Accuracy: 29.9356\n","\n","\n","Epoch [5/50], Training Loss: 2.1324, Training Accuracy: 27.2755\n","SNR [0d], Validation Loss: 2.9711, Validation Accuracy: 14.9511\n","SNR [10d], Validation Loss: 2.1310, Validation Accuracy: 27.6444\n","SNR [20d], Validation Loss: 1.8656, Validation Accuracy: 33.4878\n","SNR [30d], Validation Loss: 1.8223, Validation Accuracy: 34.4722\n","SNR [40d], Validation Loss: 1.8103, Validation Accuracy: 34.8233\n","\n","\n","Epoch [6/50], Training Loss: 2.0165, Training Accuracy: 30.0775\n","SNR [0d], Validation Loss: 2.8846, Validation Accuracy: 15.5878\n","SNR [10d], Validation Loss: 2.0306, Validation Accuracy: 29.5044\n","SNR [20d], Validation Loss: 1.7401, Validation Accuracy: 36.2056\n","SNR [30d], Validation Loss: 1.6937, Validation Accuracy: 37.6311\n","SNR [40d], Validation Loss: 1.6820, Validation Accuracy: 37.9278\n","\n","\n","Epoch [7/50], Training Loss: 1.9224, Training Accuracy: 32.5875\n","SNR [0d], Validation Loss: 2.8405, Validation Accuracy: 16.1456\n","SNR [10d], Validation Loss: 1.9839, Validation Accuracy: 29.6078\n","SNR [20d], Validation Loss: 1.6957, Validation Accuracy: 35.9578\n","SNR [30d], Validation Loss: 1.6551, Validation Accuracy: 36.9489\n","SNR [40d], Validation Loss: 1.6460, Validation Accuracy: 37.0678\n","\n","\n","Epoch [8/50], Training Loss: 1.8446, Training Accuracy: 34.7268\n","SNR [0d], Validation Loss: 2.8084, Validation Accuracy: 16.8844\n","SNR [10d], Validation Loss: 1.8970, Validation Accuracy: 33.2856\n","SNR [20d], Validation Loss: 1.5663, Validation Accuracy: 41.6222\n","SNR [30d], Validation Loss: 1.5061, Validation Accuracy: 43.7111\n","SNR [40d], Validation Loss: 1.4940, Validation Accuracy: 44.0167\n","\n","\n","Epoch [9/50], Training Loss: 1.7797, Training Accuracy: 36.5415\n","SNR [0d], Validation Loss: 2.7753, Validation Accuracy: 17.3356\n","SNR [10d], Validation Loss: 1.8772, Validation Accuracy: 33.3833\n","SNR [20d], Validation Loss: 1.5844, Validation Accuracy: 40.7544\n","SNR [30d], Validation Loss: 1.5267, Validation Accuracy: 42.2544\n","SNR [40d], Validation Loss: 1.5258, Validation Accuracy: 42.2078\n","\n","\n","Epoch [10/50], Training Loss: 1.7198, Training Accuracy: 38.2957\n","SNR [0d], Validation Loss: 2.7724, Validation Accuracy: 17.5244\n","SNR [10d], Validation Loss: 1.8388, Validation Accuracy: 34.6333\n","SNR [20d], Validation Loss: 1.4974, Validation Accuracy: 43.7167\n","SNR [30d], Validation Loss: 1.4370, Validation Accuracy: 45.6000\n","SNR [40d], Validation Loss: 1.4299, Validation Accuracy: 45.8689\n","\n","\n","Epoch [11/50], Training Loss: 1.6664, Training Accuracy: 39.8639\n","SNR [0d], Validation Loss: 2.7539, Validation Accuracy: 18.1789\n","SNR [10d], Validation Loss: 1.7862, Validation Accuracy: 36.3467\n","SNR [20d], Validation Loss: 1.4111, Validation Accuracy: 46.5944\n","SNR [30d], Validation Loss: 1.3390, Validation Accuracy: 49.1544\n","SNR [40d], Validation Loss: 1.3319, Validation Accuracy: 49.5744\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ILlnVuvX7ZTK"},"source":[""],"execution_count":null,"outputs":[]}]}