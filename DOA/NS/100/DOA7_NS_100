{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DOA7_NS_100","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1Zfj-M21KQrk7RZVpIFCiawp0AzhXu5N2","authorship_tag":"ABX9TyPCEgQ1v9xUtejVqlw27NTm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"75epJKbjuqdO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"18RBdMHZSW5h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631703308098,"user_tz":-330,"elapsed":3075,"user":{"displayName":"Mohammad Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1sqT9k-ZJhDQXM7x7dup6__HgCR7MEKRseC9t6w=s64","userId":"07657306696827110934"}},"outputId":"ad92d028-fbf9-48dd-d20c-86c0d7373202"},"source":["pip install mat73"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: mat73 in /usr/local/lib/python3.7/dist-packages (0.52)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from mat73) (3.1.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mat73) (1.19.5)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->mat73) (1.5.2)\n"]}]},{"cell_type":"code","metadata":{"id":"-_gz9JFShJVi","executionInfo":{"status":"ok","timestamp":1631703624927,"user_tz":-330,"elapsed":723,"user":{"displayName":"Mohammad Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1sqT9k-ZJhDQXM7x7dup6__HgCR7MEKRseC9t6w=s64","userId":"07657306696827110934"}}},"source":["import scipy.io as sio\n","import numpy as np\n","import torch\n","import os\n","from os import listdir\n","from os.path import isfile, join\n","from torch import nn, optim\n","import torchvision\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import numpy as np \n","import math\n","import pandas as pd\n","import cmath\n","import scipy.io as sio\n","import numpy as np\n","import torch\n","from torch import nn, optim\n","import torchvision\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np \n","import math\n","import pandas as pd\n","import cmath\n","import mat73\n","\n","#from unet import UNet\n","# from auto import encoder, decoder\n","\n","from collections import OrderedDict\n","from torch.utils.data.sampler import SubsetRandomSampler\n","from torch.autograd import Variable\n","#==========================================================================\n","# For Plotting loss graph\n","# Bokeh\n","from bokeh.io import curdoc\n","from bokeh.layouts import column\n","from bokeh.models import ColumnDataSource\n","from bokeh.plotting import figure\n","\n","from functools import partial\n","from threading import Thread\n","from tornado import gen\n","# from AttRCNN_UNet import Att_R2U\n","import logging\n","logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)\n","import sys\n","# from dataloader import norm\n","import csv\n","from sklearn.model_selection import train_test_split\n","from sys import getsizeof\n","# import wandb\n","# import logging\n","# logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"aS-ovkA3hxXd","executionInfo":{"status":"ok","timestamp":1631703626167,"user_tz":-330,"elapsed":12,"user":{"displayName":"Mohammad Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1sqT9k-ZJhDQXM7x7dup6__HgCR7MEKRseC9t6w=s64","userId":"07657306696827110934"}}},"source":["nq_type = \"NS\" # Sub-Nyquist or Nyquist sample\n","no_samples = 100\n","no_doa = 7"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"O4U6EaZZiX6p","executionInfo":{"status":"ok","timestamp":1631703626168,"user_tz":-330,"elapsed":12,"user":{"displayName":"Mohammad Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1sqT9k-ZJhDQXM7x7dup6__HgCR7MEKRseC9t6w=s64","userId":"07657306696827110934"}}},"source":["root_dataset_path =  (\"/content/drive/MyDrive/DOA/{}/{}/New_DOA{}/\".format(nq_type, no_samples, no_doa))"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"BP6V-Z71ihqf","executionInfo":{"status":"ok","timestamp":1631703626168,"user_tz":-330,"elapsed":12,"user":{"displayName":"Mohammad Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1sqT9k-ZJhDQXM7x7dup6__HgCR7MEKRseC9t6w=s64","userId":"07657306696827110934"}}},"source":["def create_dataset(df, dataset_type):\n","  \n","    data = np.transpose(df[dataset_type], (2, 0, 1))\n","    label = df['DOA']\n","    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.15, random_state=42)\n","\n","    print(\"X_train shape\", X_train.shape)\n","    print(\"X_test shape\", X_test.shape)\n","    print(\"y_train shape\", y_train.shape)\n","    print(\"y_test shape\", y_test.shape)\n","    \n","    del data\n","    del label\n","    return X_train, X_test, y_train, y_test"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"S8T5BOaEikGq","executionInfo":{"status":"ok","timestamp":1631703626169,"user_tz":-330,"elapsed":12,"user":{"displayName":"Mohammad Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1sqT9k-ZJhDQXM7x7dup6__HgCR7MEKRseC9t6w=s64","userId":"07657306696827110934"}}},"source":["def get_data(train, test, batch_size, train_bool=True):\n","    class DOA_dataset(Dataset):\n","        def __init__(self, train, test):\n","            self.x = torch.from_numpy(np.array(train))\n","            self.y = torch.from_numpy(np.asarray(test))\n","            self.n_sample = len(self.y)\n","        def __getitem__(self, index):\n","            return self.x[index], self.y[index]\n","        def __len__(self):\n","            return self.n_sample\n","\n","    dataset = DOA_dataset(train, test)\n","\n","    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=train_bool)\n","    return loader"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"FDf_p6puuguB","executionInfo":{"status":"ok","timestamp":1631703626169,"user_tz":-330,"elapsed":12,"user":{"displayName":"Mohammad Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1sqT9k-ZJhDQXM7x7dup6__HgCR7MEKRseC9t6w=s64","userId":"07657306696827110934"}}},"source":[""],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"5S3HvR-fyHKI","executionInfo":{"status":"ok","timestamp":1631703626170,"user_tz":-330,"elapsed":12,"user":{"displayName":"Mohammad Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1sqT9k-ZJhDQXM7x7dup6__HgCR7MEKRseC9t6w=s64","userId":"07657306696827110934"}}},"source":["# new_train_dataset_list = np.load(\"/content/drive/MyDrive/DOA/NS/saved/100/new_train_dataset_list_2.npy\")\n","# train_dataset_list_label = np.load(\"/content/drive/MyDrive/DOA/NS/saved/100/train_dataset_list_label_2.npy\")\n","# doa_train_loader = get_data(new_train_dataset_list, train_dataset_list_label, 64, True)\n","# del new_train_dataset_list\n","# del train_dataset_list_label\n","\n","# new_test_dataset_list = np.load(\"/content/drive/MyDrive/DOA/NS/saved/100/new_test_dataset_list_2.npy\")\n","# test_dataset_list_label = np.load(\"/content/drive/MyDrive/DOA/NS/saved/100/test_dataset_list_label_2.npy\")\n","\n","# test_dataset_list = []\n","# logging.info('Creating Validation dataloader')\n","# for idx, data in enumerate(new_test_dataset_list):\n","#     f = get_data(data, test_dataset_list_label[idx], 128, False)\n","#     test_dataset_list.append(f)\n","# del new_test_dataset_list"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"JKVlVa3_Qsky","executionInfo":{"status":"ok","timestamp":1631703626170,"user_tz":-330,"elapsed":12,"user":{"displayName":"Mohammad Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1sqT9k-ZJhDQXM7x7dup6__HgCR7MEKRseC9t6w=s64","userId":"07657306696827110934"}}},"source":["def saveList(myList,filename):\n","    # the filename should mention the extension 'npy'\n","    np.save(filename, myList)\n","    logging.info(\"Saved successfully!\")"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"WAFSQpEEiltN","executionInfo":{"status":"ok","timestamp":1631705564612,"user_tz":-330,"elapsed":713,"user":{"displayName":"Mohammad Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1sqT9k-ZJhDQXM7x7dup6__HgCR7MEKRseC9t6w=s64","userId":"07657306696827110934"}}},"source":["def create_dataloader(root_path, dataset_type, ss):\n","    # Loading all dataset \n","    logging.info('Data prepration started')\n","    df1  = mat73.loadmat(root_path + \"SNR_{}_0_{}_{}.mat\".format(nq_type, no_doa, no_samples))\n","    df2  = mat73.loadmat(root_path + \"SNR_{}_10_{}_{}.mat\".format(nq_type, no_doa, no_samples))\n","    df3  = mat73.loadmat(root_path + \"SNR_{}_20_{}_{}.mat\".format(nq_type, no_doa, no_samples))\n","    df4  = mat73.loadmat(root_path + \"SNR_{}_30_{}_{}.mat\".format(nq_type, no_doa, no_samples))\n","    df5  = mat73.loadmat(root_path + \"SNR_{}_40_{}_{}.mat\".format(nq_type, no_doa, no_samples))\n","    df = [df1, df2, df3, df4, df5]\n","\n","    new_train_dataset_list = []\n","    new_test_dataset_list = []\n","    train_dataset_list_label = []\n","    test_dataset_list_label = []\n","\n","    dataset_len = 0\n","    if dataset_type == \"SNS\":\n","        dataset_len = ss//10\n","    if dataset_type == \"NS\":\n","        dataset_len = ss\n","    logging.info('Dividing your dataset into train and test')\n","    for file in df:\n","        X_train, X_test, y_train, y_test = create_dataset(file, dataset_type+\"_data\")\n","        new_train_dataset_list.extend(X_train)\n","        new_test_dataset_list.append(X_test.tolist())\n","        train_dataset_list_label.extend(y_train)\n","        test_dataset_list_label.append(y_test.tolist())\n","\n","    # Deleteing all unused memory\n","    del df\n","    del df1\n","    del df2\n","    del df3\n","    del df4\n","    del df5\n","\n","    # Dividing into different channels\n","    logging.info('Dividing your dataset into 2 channel(train)')\n","\n","    for idx, data in enumerate(new_train_dataset_list):\n","        new = np.zeros((2, 8, dataset_len))\n","        for j in range(0, data.shape[0]):\n","            for k in range(0, data.shape[1]):\n","                new[0][j][k] = data[j][k].real\n","                new[1][j][k] = data[j][k].imag\n","                # new[2][j][k] = cmath.phase(data[j][k])\n","        new_train_dataset_list[idx] = new\n","    del new\n","\n","    print(\"new_train_dataset_list\", np.array(new_train_dataset_list).shape)\n","    print(\"new_train_dataset_list value\", new_train_dataset_list[0])\n","    \n","    logging.info('Saving (train data)')\n","    # saveList(new_train_dataset_list, \"/content/drive/MyDrive/DOA/NS/saved/100/new_train_dataset_list_2.npy\")\n","    # saveList(train_dataset_list_label, \"/content/drive/MyDrive/DOA/NS/saved/100/train_dataset_list_label_2.npy\")\n","    \n","    print(\"Max bfore train\", np.max(new_train_dataset_list[0][1]))\n","\n","    for idx, data in enumerate(new_train_dataset_list):\n","        data[0] = data[0]/(np.max(data[0])) \n","        data[1] = data[1]/(np.max(data[1])) \n","        # data[2] = data[2]/(np.max(data[2]))\n","        \n","    print(\"Max after train\", np.max(new_train_dataset_list[0][1]))\n","\n","    logging.info('Dividing your dataset into 3 channel(test)')\n","    for idx, data in enumerate(new_test_dataset_list):\n","        for i, ndata in enumerate(data):\n","            new = np.zeros((2, 8, dataset_len))\n","            for j in range(0, 8):\n","                for k in range(0, dataset_len):\n","                    new[0][j][k] = ndata[j][k].real\n","                    new[1][j][k] = ndata[j][k].imag\n","                    # new[2][j][k] = cmath.phase(ndata[j][k])\n","            new_test_dataset_list[idx][i] = new\n","    del new\n","\n","    logging.info('Saving (test data)')\n","    saveList(new_test_dataset_list, \"/content/drive/MyDrive/DOA/NS/saved/100/new_test_dataset_list_2.npy\")\n","    saveList(test_dataset_list_label, \"/content/drive/MyDrive/DOA/NS/saved/100/test_dataset_list_label_2.npy\")\n","    \n","    print(\"Min before test\", np.min(new_test_dataset_list[0][1][1]))  \n","    print(\"new_test_dataset_list value\", new_test_dataset_list[0][1][1])\n","\n","    for idx, data in enumerate(new_test_dataset_list):\n","        for i, ndata in enumerate(data):\n","            new_test_dataset_list[idx][i][0] = new_test_dataset_list[idx][i][0]/(np.max(new_test_dataset_list[idx][i][0]))\n","            new_test_dataset_list[idx][i][1] = new_test_dataset_list[idx][i][1]/(np.max(new_test_dataset_list[idx][i][1]))\n","            # new_test_dataset_list[idx][i][2] = new_test_dataset_list[idx][i][2]/(np.max(new_test_dataset_list[idx][i][2]))\n","    print(\"Min after test\", np.min(new_test_dataset_list[0][1][1]))\n","    print(\"new_test_dataset_list value\", new_test_dataset_list[0][1][1]) \n","\n","    # Generaring train loader\n","    logging.info('Creating Train dataloader')\n","    doa_train_loader = get_data(new_train_dataset_list, train_dataset_list_label, 64, True)\n","    \n","    # Deleteing all unused memory\n","    del new_train_dataset_list\n","    del train_dataset_list_label\n","\n","    test_dataset_list = []\n","    logging.info('Creating Validation dataloader')\n","    for idx, data in enumerate(new_test_dataset_list):\n","        print(\"Test shape with SNR -\",idx*10, np.array(data).shape)\n","        print(\"Test shape with SNR -\",idx*10, \"Value\", data[0])\n","\n","        f = get_data(data, test_dataset_list_label[idx], 128, False)\n","        test_dataset_list.append(f)\n","\n","    # Deleteing all unused memory\n","    del new_test_dataset_list\n","    \n","    logging.info('Your dataset is ready !!')\n","    return doa_train_loader ,test_dataset_list"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"id":"peHL-OsRir3o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631705725639,"user_tz":-330,"elapsed":161035,"user":{"displayName":"Mohammad Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1sqT9k-ZJhDQXM7x7dup6__HgCR7MEKRseC9t6w=s64","userId":"07657306696827110934"}},"outputId":"4d5fcbd6-68b1-4831-f023-89d8556686d9"},"source":["doa_train_loader , test_dataset_list = create_dataloader(root_dataset_path, nq_type, no_samples)"],"execution_count":49,"outputs":[{"output_type":"stream","name":"stderr","text":["2021-09-15 11:32:44,138 - Data prepration started\n","2021-09-15 11:32:55,294 - Dividing your dataset into train and test\n"]},{"output_type":"stream","name":"stdout","text":["X_train shape (85000, 8, 100)\n","X_test shape (15000, 8, 100)\n","y_train shape (85000, 7)\n","y_test shape (15000, 7)\n"]},{"output_type":"stream","name":"stderr","text":["2021-09-15 11:32:56,674 - Dividing your dataset into 2 channel(train)\n","2021-09-15 11:35:07,218 - Saving (train data)\n"]},{"output_type":"stream","name":"stdout","text":["new_train_dataset_list (85000, 2, 8, 100)\n","new_train_dataset_list value [[[-0.14819796 -0.4023653  -0.31143443 ...  0.3425214  -0.30362963\n","   -0.18849743]\n","  [-0.48971179 -0.54414971 -0.33568475 ... -0.14886674 -0.40836389\n","   -0.53270328]\n","  [ 0.09083362 -0.22129414 -0.24019885 ... -0.30529817 -0.36910521\n","   -0.09081472]\n","  ...\n","  [-0.04031344  0.09845182  0.26214472 ... -0.06728842 -0.45894516\n","   -0.05532999]\n","  [ 0.32413765  0.52708226  0.17266003 ...  0.09390124  0.18221882\n","    0.05503769]\n","  [-0.1747349   0.07217799  0.06327772 ... -0.0313718   0.35762831\n","    0.07560452]]\n","\n"," [[ 0.06883685  0.00201893  0.03227636 ... -0.0712463   0.29672879\n","    0.27569337]\n","  [-0.01283265 -0.00319191 -0.1049133  ...  0.25402881  0.48949564\n","    0.41098393]\n","  [ 0.15319905 -0.11991166 -0.08400392 ...  0.07351781 -0.03400947\n","    0.13275255]\n","  ...\n","  [-0.53217772 -0.21812413  0.2188968  ...  0.09396837 -0.02296267\n","   -0.15928334]\n","  [-0.5699447  -0.16047399 -0.16763632 ... -0.24191711 -0.35575663\n","   -0.28894737]\n","  [-0.32198393  0.0405278   0.16122567 ... -0.26883193 -0.05775709\n","   -0.29437779]]]\n","Max bfore train 0.6140686995855547\n"]},{"output_type":"stream","name":"stderr","text":["2021-09-15 11:35:08,814 - Dividing your dataset into 3 channel(test)\n"]},{"output_type":"stream","name":"stdout","text":["Max after train 1.0\n"]},{"output_type":"stream","name":"stderr","text":["2021-09-15 11:35:22,462 - Saving (test data)\n","2021-09-15 11:35:23,638 - Saved successfully!\n","2021-09-15 11:35:23,666 - Saved successfully!\n"]},{"output_type":"stream","name":"stdout","text":["Min before test -0.5252984099201539\n","new_test_dataset_list value [[ 2.00928889e-01  7.73874121e-02 -1.02136781e-02 -1.53005618e-01\n","   6.20336016e-03  1.61456216e-02  6.45958850e-01  3.38151466e-01\n","   2.74801663e-01  2.28024412e-01  3.54384912e-01  2.93606994e-01\n","   3.06733351e-01  1.68625513e-01 -1.47884585e-01 -1.46399246e-01\n","  -3.16006430e-01 -1.78946886e-01 -2.33769052e-01  9.81196874e-02\n","   1.36425637e-01 -1.12680685e-01  8.33553924e-02  7.16611096e-03\n","  -4.52768854e-02 -3.41739028e-01 -1.72042740e-01 -2.27171078e-01\n","  -2.45653723e-01  1.19449047e-03 -2.49038249e-01  1.21718040e-01\n","   3.46920741e-01  8.05067685e-02  1.04454835e-01  2.05628392e-01\n","   3.18561966e-01  1.10813538e-01  1.68053009e-01  1.94876225e-01\n","  -6.19773225e-02 -2.14459661e-01 -1.01696855e-01 -2.50511901e-01\n","  -4.18484680e-01 -8.45339404e-02 -1.81840216e-02 -7.68367172e-03\n","   2.35621862e-01  1.12232923e-01  3.31027118e-01 -5.49771069e-02\n","   1.15854925e-01  8.29808713e-02  2.35323857e-01  2.99710242e-01\n","   2.28446366e-01  3.44079522e-01  7.80243485e-02  4.08444240e-01\n","  -2.31909499e-01 -4.55985494e-02 -3.35735765e-01  3.30529527e-03\n","  -2.18431860e-01 -1.07995615e-01 -4.62509349e-01 -9.60831619e-02\n","  -1.08288110e-02  7.17663748e-02  3.00277881e-01 -1.27524318e-01\n","   5.66097682e-02 -9.86836603e-02 -7.80477186e-02 -2.26639468e-01\n","  -4.83097188e-02 -2.44274548e-01 -1.00246467e-01 -1.92368779e-01\n","   2.14930038e-02 -1.97789344e-01  9.56233309e-02 -2.86998169e-01\n","  -2.01802977e-01 -1.22374108e-01  6.07575569e-02 -1.41598938e-01\n","   1.70529808e-01  2.46428781e-02  7.36760814e-02 -2.02766718e-01\n","   5.89421307e-02  1.12201183e-03 -7.46158383e-02  2.35864899e-01\n","  -1.53664831e-02 -6.06064591e-02 -1.25246436e-01 -4.28451333e-01]\n"," [-1.52211398e-02  2.18027848e-02  8.61253042e-02  1.74105880e-01\n","   5.74171187e-02 -1.71250334e-01  4.83211517e-02  2.53382613e-01\n","   1.59089230e-01  6.43700073e-02  1.78216317e-01  2.19005818e-01\n","   8.82869701e-02  3.10107291e-01 -1.56407329e-01  9.62783268e-02\n","   2.52790831e-01  1.54104306e-01  7.14510970e-02  1.08009154e-01\n","  -5.35704998e-02 -3.78793001e-01 -4.27739906e-01 -2.04522460e-01\n","  -2.60028295e-01 -2.42847926e-01 -5.23908125e-01 -1.08870900e-01\n","  -5.18759162e-01 -2.40234737e-01 -8.15516222e-02  8.78175198e-02\n","   2.94939036e-01  4.53195317e-02  4.00354138e-01  2.76533147e-01\n","   3.67285622e-01  1.30076699e-01 -1.82011999e-02 -2.21554066e-01\n","   9.74925929e-02 -1.93833493e-01 -2.44630548e-01 -2.78458158e-01\n","  -2.17758655e-01 -2.12296511e-01 -5.58780481e-02  1.94296607e-01\n","   2.52733727e-01 -3.68015017e-02  1.82479410e-01  1.17862534e-01\n","   2.17028887e-01  1.36860435e-01  2.35685724e-01  2.10692778e-01\n","   1.76600996e-02  8.24409231e-02  6.70390551e-02 -3.21265455e-02\n","   7.25113142e-02 -9.48067412e-03  2.17777545e-02 -1.31921302e-01\n","  -9.65008872e-02 -6.38450344e-02  1.89316851e-01 -1.16578330e-01\n","  -3.44665101e-01 -1.84415317e-01  6.34851816e-02  1.16884705e-01\n","  -9.00726436e-02  1.27470987e-01  1.81120096e-01 -2.07273254e-01\n","  -6.18181307e-02  3.25199122e-01 -6.12733247e-02 -2.25501436e-01\n","  -9.83573138e-02 -6.77732692e-02  1.38863323e-01 -1.18379913e-01\n","  -9.13788808e-02  1.98327951e-01 -2.34971806e-02 -5.91359432e-02\n","  -9.82680817e-02  3.47690424e-02  1.34554480e-01  3.76479703e-01\n","   6.38069575e-03  1.15138095e-01 -1.02009657e-02  1.80006742e-02\n","  -1.09600662e-01 -1.72230488e-01 -4.40409856e-02 -3.98803130e-02]\n"," [ 3.31909893e-01  1.76187415e-01 -1.01644815e-02  8.51316969e-02\n","  -1.32043027e-01 -1.79842048e-01 -7.96226387e-02  8.20676741e-02\n","  -1.19759548e-01 -3.93351940e-01  5.32610185e-03  1.34024194e-01\n","   1.25570620e-02  2.97245011e-02  6.25378158e-02  1.66804642e-01\n","   5.46310018e-02  2.18115683e-01  6.59445380e-02 -5.34081945e-02\n","   7.35439701e-02 -9.83310393e-02 -8.28967841e-02 -3.98779198e-01\n","  -5.25298410e-01 -3.15397899e-01 -4.61377701e-01 -4.89266623e-01\n","  -3.04484769e-01 -2.00291750e-01 -5.08761666e-02  1.61617700e-01\n","   1.86461839e-01  2.87242870e-01  3.65692686e-01  2.58948178e-01\n","   2.26722418e-01  2.96244727e-01  2.26409749e-01 -6.62087695e-02\n","  -6.88177595e-02  8.20766014e-02 -6.06339179e-02  2.46767517e-01\n","   3.07094344e-02  8.47087614e-02  1.36840702e-01  3.34516551e-01\n","   1.04733706e-01  8.92618318e-02 -6.07233300e-02  1.86775498e-01\n","  -2.66210902e-01  1.83196711e-01  3.49210818e-02  1.26208297e-01\n","   3.50213191e-02 -1.05535618e-01 -2.17410010e-02  2.42979107e-02\n","   1.58752861e-02  2.90080046e-02 -1.50762880e-01  7.81889185e-02\n","   7.31581680e-02 -2.48152783e-01 -1.44283195e-01 -2.29076669e-01\n","  -2.52099955e-02 -1.54185738e-01  7.20436461e-04  3.83579740e-02\n","  -1.59033887e-01  1.86983155e-01  1.28827238e-01  5.61558358e-03\n","  -1.27511780e-01 -3.05487021e-01 -2.34450003e-01 -2.67001741e-01\n","  -2.17855110e-01 -1.51850976e-01 -1.73336667e-01  1.91437067e-02\n","   1.50091325e-01  1.29459782e-01 -1.65755910e-01  1.05965748e-01\n","   3.57086133e-01  3.69554018e-01  2.22394708e-02 -9.17075889e-03\n","   2.44079265e-01  1.01571679e-01 -1.10854859e-02  1.36601749e-01\n","   1.83369346e-01 -1.54845723e-02  6.87781540e-02  4.38219041e-02]\n"," [ 2.40906825e-01  1.16175605e-02 -2.18599755e-02 -2.10687727e-01\n","  -4.22817248e-01 -3.47053941e-01 -3.05206291e-01 -3.67385604e-01\n","  -4.46623142e-02 -2.81590775e-01 -8.23762614e-03 -3.64127100e-02\n","   1.07439466e-01  1.67127288e-01 -8.59827592e-02  4.46262645e-02\n","   5.04023234e-01 -1.60606704e-02  2.53109649e-01  2.82400692e-01\n","   1.54847759e-01 -3.30381186e-01  1.43500871e-01 -1.17017921e-01\n","  -1.52445889e-01 -1.11876268e-01 -3.89200580e-01 -8.29982694e-02\n","  -1.10799184e-01 -1.61052381e-01 -1.98542500e-01  1.80741836e-01\n","   7.96798975e-02  9.00172321e-02  1.98237570e-01  1.36874572e-01\n","   2.21769862e-01 -4.79539291e-04  2.59003611e-01  2.44801390e-01\n","   9.53132481e-02  4.44626025e-01  1.43433207e-01 -1.24104547e-01\n","  -1.05066242e-01 -3.45184265e-01 -2.33309181e-01 -1.33841148e-01\n","  -5.33586265e-03 -1.26206573e-01 -2.83361610e-01 -2.00569355e-01\n","  -1.26889286e-01 -1.77250703e-01  9.53772783e-02 -2.39354606e-01\n","  -3.32529637e-02 -2.97884284e-01 -6.08010638e-02  5.55373190e-02\n","   1.83777699e-01 -1.29391265e-01 -7.86845050e-02 -2.80734001e-01\n","  -3.51227816e-02  4.32030876e-02 -1.23389441e-01 -3.44450482e-01\n","  -1.44609729e-01 -1.66711101e-01 -1.57392241e-01  7.52402562e-02\n","   1.31218309e-01  3.04758874e-01 -5.76958747e-02  1.16708206e-02\n","   4.47156493e-02 -2.18994289e-02 -9.53440061e-02 -3.42433942e-01\n","   5.61070697e-02  1.94699280e-01  4.17798518e-02  1.12927470e-01\n","   2.55811019e-01  7.57697202e-03  3.45233007e-03  1.28371895e-01\n","  -3.19848469e-02 -3.06133598e-01  2.16576728e-01  2.56904363e-01\n","   2.61222859e-01  1.15140561e-01  2.49999208e-01  3.82863838e-01\n","   1.76364878e-01  2.83513359e-01  2.39486601e-01  1.78622471e-02]\n"," [ 1.42843966e-01  1.17378474e-01 -2.38832206e-01 -3.98391237e-01\n","  -3.62950149e-01 -5.07613784e-01 -1.76591360e-01 -2.94697063e-01\n","  -1.89799933e-01  4.51000013e-03 -7.96357391e-02 -2.11201607e-02\n","   2.21087353e-01  3.37716736e-01  1.45088691e-01  7.41543687e-03\n","   6.57729286e-02  1.27816079e-01  1.12416577e-01  2.46937866e-03\n","   1.60440527e-02 -2.03527940e-01  3.64909143e-03  2.53441374e-01\n","   1.11603082e-01  5.34415984e-02  1.05335811e-01  1.67239478e-01\n","  -5.52529589e-02 -1.56953353e-02 -2.77077360e-01 -3.45615636e-01\n","  -1.39728115e-01 -1.03204666e-01 -9.97023679e-02  1.63416953e-01\n","   3.65143278e-02  4.32078641e-01  1.04447447e-01  1.21128254e-01\n","  -7.48232455e-03  1.16175206e-01  4.89479121e-02  7.29312540e-02\n","  -4.04454205e-02  2.38328231e-01  7.00055364e-02 -1.18166826e-01\n","   2.81974522e-01 -4.13569395e-02 -1.30820416e-01  5.51428624e-02\n","  -1.43272992e-01 -8.78586083e-02 -2.40445222e-01 -2.33064792e-01\n","  -1.41804390e-01  2.13123293e-02 -3.25484921e-01 -1.10332480e-01\n","  -3.38495160e-01 -3.78621584e-02 -1.42129780e-01 -3.02317740e-01\n","  -2.41209925e-01  1.97215821e-01 -1.69935720e-02 -2.18127608e-01\n","  -1.16082313e-01 -8.24980026e-02 -1.94451629e-02 -1.49567772e-01\n","   7.93473189e-02  4.28947806e-02 -1.07564175e-01  3.27440925e-02\n","  -1.08067736e-01  9.26982096e-02  2.07297979e-01  4.19547122e-01\n","   3.00344606e-01  1.50851552e-02  6.93512714e-02  1.66002591e-01\n","   1.77912784e-01  1.17655774e-02  1.89233373e-01 -1.67732423e-01\n","  -1.04485577e-01 -9.06819441e-02 -4.81047744e-02 -7.87817317e-02\n","   1.87993060e-01 -4.78161886e-02  3.83221440e-01  3.42975704e-01\n","   2.20261622e-01  1.28943477e-01  1.91722415e-01  5.39771929e-01]\n"," [ 1.45026950e-02 -6.22390757e-02 -7.98376649e-03 -3.30943653e-01\n","  -8.03331018e-02 -2.49210734e-01 -1.71775084e-01 -2.62244389e-01\n","  -3.26303587e-01  7.19657863e-02  5.00504725e-02 -1.35526624e-01\n","   4.43979213e-02  1.49709393e-03 -5.24514678e-02  2.54405320e-02\n","   1.01835268e-01  1.70183472e-01  3.28418751e-04  2.41976945e-01\n","   2.20636767e-01  2.17709979e-01  3.92631197e-02  1.17587488e-01\n","   6.16887453e-02  3.23747743e-01  3.02083202e-01  2.83473750e-02\n","   2.27423398e-01 -1.96440926e-01 -1.35155595e-01  3.17206083e-02\n","  -3.86439424e-02  2.23112651e-01  2.90346954e-02 -9.28283016e-02\n","  -2.58747822e-01 -9.03178426e-02  2.58409187e-02 -6.47417983e-02\n","   9.10482568e-02  1.90558821e-02 -6.41697129e-02 -2.14085568e-01\n","  -9.45536503e-02  7.33916209e-02 -2.09155383e-01 -2.54500002e-01\n","   8.44949578e-02 -8.22523787e-02 -1.22594483e-01  5.30327948e-02\n","  -2.50363507e-02  6.16746535e-02 -3.02150246e-01 -1.50207487e-01\n","  -2.16303323e-01 -3.41983340e-02 -2.51390099e-01 -1.19130030e-01\n","  -5.58667559e-02  1.05128545e-01  5.46924937e-02  1.45936741e-01\n","   1.79477372e-01  8.85488066e-02  9.50456655e-02 -2.04929314e-01\n","  -2.31669122e-01 -2.38196529e-01  4.90132631e-02 -1.75550047e-01\n","   7.54401234e-02  4.59443822e-02  8.68995560e-02 -1.42907167e-02\n","  -2.88093574e-02  3.09323929e-01  2.50950876e-01  2.77311192e-01\n","   2.02774714e-01  1.13373168e-01  6.18305985e-02  2.19324528e-01\n","   2.19203010e-02  4.08132711e-02 -2.42440035e-01 -3.21789818e-01\n","  -7.53901646e-02 -1.94870194e-01  2.62217943e-01 -2.46513723e-01\n","  -8.64477108e-02 -1.11648646e-01  1.16084444e-01  5.43808644e-02\n","   2.00963181e-01  2.09282223e-01  9.73754005e-02 -3.78514719e-04]\n"," [ 8.95651376e-02  2.69386574e-01 -9.24236795e-02  7.53891978e-02\n","  -9.40048599e-02  2.29559935e-02  1.23055424e-01 -4.46935324e-02\n","   1.31565265e-01 -1.59250631e-01 -8.67283038e-02 -1.57349267e-01\n","  -2.95047861e-01 -2.10510109e-01  4.52119771e-02 -2.06153752e-01\n","   9.28115550e-02  9.96312604e-02  3.80227359e-01  9.25587277e-02\n","   1.50536672e-01  3.54367169e-01  1.43197598e-01  1.41381416e-01\n","   1.07890116e-01  3.52796114e-01  2.48531159e-01  1.61438593e-01\n","   1.52073703e-01 -1.31347450e-01 -1.47697830e-03 -1.38206386e-01\n","  -1.90493821e-01  6.00502974e-02  5.24274742e-02 -5.39450949e-02\n","   3.19408271e-02 -2.58526399e-01  1.65830434e-02 -3.72979466e-01\n","  -1.39150344e-01 -2.67057941e-01 -1.85437634e-01 -1.09650910e-02\n","  -3.23306688e-02 -1.26545837e-01  2.67076052e-02 -4.37651392e-02\n","   1.84817242e-03  1.64145749e-01  1.18815546e-01  1.79232691e-01\n","  -2.20916678e-02 -2.16243317e-01 -9.74887322e-02  1.19135841e-02\n","  -1.05246481e-01 -3.59273146e-02 -1.44849198e-02  2.61974985e-02\n","   1.18560999e-01  4.01406108e-01  2.58420208e-01  6.12259328e-02\n","  -4.57932620e-02 -4.63260197e-02 -8.81032597e-02 -2.98520829e-01\n","   1.48748001e-01 -3.11390844e-01 -6.77050436e-02  7.87435815e-02\n","   1.06130675e-01  2.86557477e-01  3.61746553e-01  3.19899460e-01\n","   4.04006640e-01  1.81745201e-01  9.27808469e-02  2.50735906e-01\n","   1.11319052e-01  2.34040489e-01 -9.81761871e-02 -1.73579121e-01\n","  -1.30740569e-01 -5.11035484e-01 -2.81088420e-01 -3.87150958e-01\n","  -2.48885780e-01 -1.48129529e-01  2.29320115e-01 -3.17161815e-03\n","  -1.65980503e-01 -5.61050436e-02  1.31639314e-01 -1.44235334e-01\n","   1.02829096e-01 -7.33916872e-02 -1.74775086e-01  1.46878533e-01]\n"," [ 3.90157725e-01  4.88820073e-01  2.03035828e-01  1.52620635e-01\n","   2.68880326e-01  3.08490420e-01  1.23268734e-03  3.20907164e-02\n","  -1.04204591e-03 -3.15192957e-01 -1.82247074e-01 -1.34074895e-01\n","   2.13385796e-02 -2.65895544e-01 -4.29751459e-02 -1.24941219e-01\n","  -1.89038555e-01  1.63164788e-01  7.12537892e-02  1.91922995e-02\n","   1.33494300e-01  1.94582653e-01  5.00621262e-02  1.46555228e-01\n","  -6.11079173e-02  2.91908550e-01  1.02736244e-01  8.71348872e-02\n","  -1.88589259e-02  1.53662672e-02 -1.53567400e-01 -5.39206606e-03\n","  -3.14378581e-02 -3.41481984e-01 -4.00222869e-01 -1.26637962e-01\n","  -3.05785967e-01 -3.03671062e-01 -1.68524419e-01 -1.79661499e-02\n","   2.17506940e-02  2.11154056e-01 -2.19158594e-01  9.20192352e-02\n","  -5.33226947e-04 -2.50932808e-01 -5.29286954e-02 -4.40093663e-02\n","   9.99565217e-02 -1.54746670e-01 -2.31526596e-01 -8.87438308e-02\n","  -1.02250257e-02 -5.40577806e-02 -2.12663839e-01  3.94685918e-01\n","   1.70896838e-02  8.47890399e-02  4.29481085e-01  3.63072317e-01\n","   4.05043502e-01  7.26375579e-02  1.12543915e-01  5.98408128e-02\n","  -8.61493436e-02  2.20230898e-01  1.08617748e-01 -2.84642142e-01\n","   1.43286700e-01 -4.25171736e-02 -2.12964822e-01  6.81204059e-03\n","   2.14955175e-01  7.47918583e-02  4.01230654e-02  2.26758261e-01\n","  -1.33964027e-02  8.27435899e-02  6.83769479e-02  4.01666994e-02\n","   3.85581341e-02 -7.06568678e-03  1.65336547e-02 -1.25519345e-01\n","   7.72449317e-02  1.94537708e-02  1.51798455e-02 -3.16651963e-01\n","  -3.17180246e-02 -1.07372808e-02 -4.02616049e-02  1.16399391e-01\n","  -2.41422864e-01 -2.02801987e-01 -2.98657602e-01 -3.04781714e-01\n","  -5.85757054e-02  5.05617440e-04 -6.42481496e-02  2.51197064e-01]]\n"]},{"output_type":"stream","name":"stderr","text":["2021-09-15 11:35:23,976 - Creating Train dataloader\n"]},{"output_type":"stream","name":"stdout","text":["Min after test -0.8132072338960651\n","new_test_dataset_list value [[ 3.11055246e-01  1.19802387e-01 -1.58116544e-02 -2.36865891e-01\n","   9.60333644e-03  2.49948145e-02  1.00000000e+00  5.23487627e-01\n","   4.25416669e-01  3.53001452e-01  5.48618402e-01  4.54528944e-01\n","   4.74849676e-01  2.61046834e-01 -2.28938090e-01 -2.26638657e-01\n","  -4.89205202e-01 -2.77025210e-01 -3.61894649e-01  1.51897737e-01\n","   2.11198650e-01 -1.74439417e-01  1.29041335e-01  1.10937577e-02\n","  -7.00925227e-02 -5.29041483e-01 -2.66336997e-01 -3.51680417e-01\n","  -3.80293145e-01  1.84917425e-03 -3.85532683e-01  1.88430022e-01\n","   5.37063221e-01  1.24631420e-01  1.61705092e-01  3.18330482e-01\n","   4.93161393e-01  1.71548912e-01  2.60160549e-01  3.01685201e-01\n","  -9.59462395e-02 -3.32002048e-01 -1.57435500e-01 -3.87814024e-01\n","  -6.47850370e-01 -1.30865829e-01 -2.81504334e-02 -1.18949864e-02\n","   3.64762960e-01  1.73746242e-01  5.12458523e-01 -8.51093020e-02\n","   1.79353414e-01  1.28461544e-01  3.64301622e-01  4.63977299e-01\n","   3.53654673e-01  5.32664769e-01  1.20788419e-01  6.32306902e-01\n","  -3.59015901e-01 -7.05904864e-02 -5.19747914e-01  5.11688208e-03\n","  -3.38151354e-01 -1.67186525e-01 -7.16004353e-01 -1.48745020e-01\n","  -1.67639331e-02  1.11100537e-01  4.64856052e-01 -1.97418640e-01\n","   8.76368025e-02 -1.52770815e-01 -1.20824598e-01 -3.50857439e-01\n","  -7.47876104e-02 -3.78158063e-01 -1.55190175e-01 -2.97803457e-01\n","   3.32730232e-02 -3.06194960e-01  1.48033162e-01 -4.44297913e-01\n","  -3.12408410e-01 -1.89445672e-01  9.40579370e-02 -2.19207366e-01\n","   2.63994847e-01  3.81493002e-02  1.14056927e-01 -3.13900363e-01\n","   9.12475008e-02  1.73697106e-03 -1.15511752e-01  3.65139202e-01\n","  -2.37886408e-02 -9.38240246e-02 -1.93892283e-01 -6.63279609e-01]\n"," [-2.35636369e-02  3.37525909e-02  1.33329397e-01  2.69530915e-01\n","   8.88866506e-02 -2.65110284e-01  7.48053094e-02  3.92258134e-01\n","   2.46283845e-01  9.96503218e-02  2.75894226e-01  3.39039891e-01\n","   1.36675843e-01  4.80072827e-01 -2.42132032e-01  1.49047152e-01\n","   3.91342003e-01  2.38566754e-01  1.10612459e-01  1.67207484e-01\n","  -8.29317529e-02 -5.86404228e-01 -6.62178257e-01 -3.16618403e-01\n","  -4.02546222e-01 -3.75949530e-01 -8.11054952e-01 -1.68541541e-01\n","  -8.03083914e-01 -3.71904088e-01 -1.26248943e-01  1.35949093e-01\n","   4.56591060e-01  7.01585428e-02  6.19782727e-01  4.28097156e-01\n","   5.68589813e-01  2.01369946e-01 -2.81770268e-02 -3.42984798e-01\n","   1.50926940e-01 -3.00070962e-01 -3.78709182e-01 -4.31077240e-01\n","  -3.37109175e-01 -3.28653304e-01 -8.65040367e-02  3.00787902e-01\n","   3.91253603e-01 -5.69718980e-02  2.82493861e-01  1.82461365e-01\n","   3.35979431e-01  2.11871754e-01  3.64861823e-01  3.26170588e-01\n","   2.73393570e-02  1.27625658e-01  1.03782238e-01 -4.97346626e-02\n","   1.12253767e-01 -1.46769010e-02  3.37138418e-02 -2.04225551e-01\n","  -1.49391694e-01 -9.88376185e-02  2.93078810e-01 -1.80473307e-01\n","  -5.33571296e-01 -2.85490812e-01  9.82805353e-02  1.80947602e-01\n","  -1.39440219e-01  1.97336080e-01  2.80389526e-01 -3.20876870e-01\n","  -9.56997967e-02  5.03436281e-01 -9.48563901e-02 -3.49095667e-01\n","  -1.52265603e-01 -1.04918865e-01  2.14972398e-01 -1.83262313e-01\n","  -1.41462387e-01  3.07028770e-01 -3.63756617e-02 -9.15475393e-02\n","  -1.52127464e-01  5.38254757e-02  2.08301937e-01  5.82823044e-01\n","   9.87786721e-03  1.78243699e-01 -1.57919745e-02  2.78665958e-02\n","  -1.69671276e-01 -2.66627646e-01 -6.81792432e-02 -6.17381633e-02]\n"," [ 5.13825134e-01  2.72753310e-01 -1.57354938e-02  1.31791208e-01\n","  -2.04413991e-01 -2.78410997e-01 -1.23262710e-01  1.27047836e-01\n","  -1.85398106e-01 -6.08942720e-01  8.24526492e-03  2.07481008e-01\n","   1.94394147e-02  4.60160908e-02  9.68139314e-02  2.58227969e-01\n","   8.45735016e-02  3.37661885e-01  1.02087831e-01 -8.26804903e-02\n","   1.13852407e-01 -1.52224928e-01 -1.28331370e-01 -6.17344584e-01\n","  -8.13207234e-01 -4.88263144e-01 -7.14252464e-01 -7.57426921e-01\n","  -4.71368677e-01 -3.10068900e-01 -7.87606928e-02  2.50198136e-01\n","   2.88659005e-01  4.44676731e-01  5.66123810e-01  4.00874108e-01\n","   3.50985852e-01  4.58612382e-01  3.50501815e-01 -1.02496884e-01\n","  -1.06535826e-01  1.27061656e-01 -9.38665333e-02  3.82017395e-01\n","   4.75408525e-02  1.31136467e-01  2.11841207e-01  5.17860466e-01\n","   1.62136807e-01  1.38185012e-01 -9.40049509e-02  2.89144576e-01\n","  -4.12117431e-01  2.83604305e-01  5.40608457e-02  1.95381326e-01\n","   5.42160218e-02 -1.63378236e-01 -3.36569442e-02  3.76152609e-02\n","   2.45763118e-02  4.49068924e-02 -2.33393939e-01  1.21043188e-01\n","   1.13255152e-01 -3.84161906e-01 -2.23362827e-01 -3.54630436e-01\n","  -3.90272468e-02 -2.38692817e-01  1.11529776e-03  5.93814512e-02\n","  -2.46198170e-01  2.89466047e-01  1.99435673e-01  8.69340760e-03\n","  -1.97399231e-01 -4.72920250e-01 -3.62948820e-01 -4.13341718e-01\n","  -3.37258495e-01 -2.35078405e-01 -2.68340107e-01  2.96361087e-02\n","   2.32354313e-01  2.00414905e-01 -2.56604442e-01  1.64044115e-01\n","   5.52800125e-01  5.72101485e-01  3.44286185e-02 -1.41971255e-02\n","   3.77855748e-01  1.57241717e-01 -1.71612880e-02  2.11471286e-01\n","   2.83871558e-01 -2.39714531e-02  1.06474513e-01  6.78400861e-02]\n"," [ 3.72944538e-01  1.79849855e-02 -3.38411270e-02 -3.26162769e-01\n","  -6.54557559e-01 -5.37269426e-01 -4.72485655e-01 -5.68744594e-01\n","  -6.91411134e-02 -4.35926801e-01 -1.27525556e-02 -5.63700149e-02\n","   1.66325557e-01  2.58727452e-01 -1.33108725e-01  6.90853054e-02\n","   7.80271427e-01 -2.48633027e-02  3.91835562e-01  4.37180622e-01\n","   2.39717683e-01 -5.11458564e-01  2.22151722e-01 -1.81153832e-01\n","  -2.35999382e-01 -1.73194110e-01 -6.02516058e-01 -1.28488478e-01\n","  -1.71526691e-01 -2.49322972e-01 -3.07360909e-01  2.79803947e-01\n","   1.23351352e-01  1.39354437e-01  3.06888853e-01  2.11893640e-01\n","   3.43318869e-01 -7.42368171e-04  4.00959924e-01  3.78973660e-01\n","   1.47553127e-01  6.88319425e-01  2.22046973e-01 -1.92124539e-01\n","  -1.62651602e-01 -5.34375006e-01 -3.61182730e-01 -2.07197638e-01\n","  -8.26037549e-03 -1.95378658e-01 -4.38668206e-01 -3.10498656e-01\n","  -1.96435557e-01 -2.74399372e-01  1.47652251e-01 -3.70541569e-01\n","  -5.14784551e-02 -4.61150558e-01 -9.41252895e-02  8.59765587e-02\n","   2.84503725e-01 -2.00308835e-01 -1.21810399e-01 -4.34600440e-01\n","  -5.43730945e-02  6.68821050e-02 -1.91017495e-01 -5.33239047e-01\n","  -2.23868329e-01 -2.58083159e-01 -2.43656761e-01  1.16478404e-01\n","   2.03137258e-01  4.71793015e-01 -8.93181890e-02  1.80674367e-02\n","   6.92236809e-02 -3.39022043e-02 -1.47600743e-01 -5.30117270e-01\n","   8.68585820e-02  3.01411274e-01  6.46788131e-02  1.74821461e-01\n","   3.96017515e-01  1.17298060e-02  5.34450464e-03  1.98730762e-01\n","  -4.95153010e-02 -4.73921207e-01  3.35279450e-01  3.97710106e-01\n","   4.04395511e-01  1.78247517e-01  3.87020330e-01  5.92706234e-01\n","   2.73028038e-01  4.38903126e-01  3.70745909e-01  2.76522987e-02]\n"," [ 2.21134777e-01  1.81711999e-01 -3.69732849e-01 -6.16743988e-01\n","  -5.61878126e-01 -7.85829907e-01 -2.73378652e-01 -4.56216464e-01\n","  -2.93826662e-01  6.98186909e-03 -1.23282991e-01 -3.26958299e-02\n","   3.42262287e-01  5.22814628e-01  2.24609804e-01  1.14797357e-02\n","   1.01822165e-01  1.97870312e-01  1.74030555e-01  3.82281110e-03\n","   2.48375770e-02 -3.15078801e-01  5.64910818e-03  3.92349101e-01\n","   1.72771194e-01  8.27322025e-02  1.63068918e-01  2.58901133e-01\n","  -8.55363447e-02 -2.42977324e-02 -4.28939645e-01 -5.35042806e-01\n","  -2.16311171e-01 -1.59769722e-01 -1.54347863e-01  2.52983534e-01\n","   5.65273280e-02  6.68894993e-01  1.61693654e-01  1.87516982e-01\n","  -1.15832836e-02  1.79849236e-01  7.57755887e-02  1.12903870e-01\n","  -6.26129985e-02  3.68952652e-01  1.08374607e-01 -1.82932436e-01\n","   4.36520874e-01 -6.40241084e-02 -2.02521285e-01  8.53659058e-02\n","  -2.21798946e-01 -1.36012701e-01 -3.72229937e-01 -3.60804395e-01\n","  -2.19525423e-01  3.29933234e-02 -5.03878723e-01 -1.70804192e-01\n","  -5.24019695e-01 -5.86138859e-02 -2.20029155e-01 -4.68013929e-01\n","  -3.73413763e-01  3.05307097e-01 -2.63075148e-02 -3.37680345e-01\n","  -1.79705430e-01 -1.27714022e-01 -3.01027890e-02 -2.31543808e-01\n","   1.22836492e-01  6.64048191e-02 -1.66518617e-01  5.06906786e-02\n","  -1.67298173e-01  1.43504822e-01  3.20915146e-01  6.49495121e-01\n","   4.64959348e-01  2.33531211e-02  1.07361748e-01  2.56986324e-01\n","   2.75424331e-01  1.82141283e-02  2.92949578e-01 -2.59664254e-01\n","  -1.61752683e-01 -1.40383469e-01 -7.44703388e-02 -1.21960914e-01\n","   2.91029468e-01 -7.40235830e-02  5.93259834e-01  5.30955963e-01\n","   3.40983984e-01  1.99615621e-01  2.96802831e-01  8.35613490e-01]\n"," [ 2.24514224e-02 -9.63514559e-02 -1.23595590e-02 -5.12329311e-01\n","  -1.24362569e-01 -3.85799706e-01 -2.65922642e-01 -4.05976927e-01\n","  -5.05146089e-01  1.11409243e-01  7.74824471e-02 -2.09806899e-01\n","   6.87318106e-02  2.31763050e-03 -8.11993949e-02  3.93841372e-02\n","   1.57649776e-01  2.63458690e-01  5.08420545e-04  3.74601176e-01\n","   3.41564740e-01  3.37033820e-01  6.07826948e-02  1.82035570e-01\n","   9.54994971e-02  5.01189423e-01  4.67650844e-01  4.38841809e-02\n","   3.52071030e-01 -3.04107492e-01 -2.09232515e-01  4.91062369e-02\n","  -5.98241550e-02  3.45397623e-01  4.49482121e-02 -1.43706215e-01\n","  -4.00563939e-01 -1.39819808e-01  4.00039704e-02 -1.00225886e-01\n","   1.40950552e-01  2.95001487e-02 -9.93402488e-02 -3.31422920e-01\n","  -1.46377204e-01  1.13616557e-01 -3.23790568e-01 -3.93987948e-01\n","   1.30805480e-01 -1.27333775e-01 -1.89786831e-01  8.20993393e-02\n","  -3.87584297e-02  9.54776817e-02 -4.67754634e-01 -2.32534142e-01\n","  -3.34856195e-01 -5.29419699e-02 -3.89173550e-01 -1.84423558e-01\n","  -8.64865553e-02  1.62748053e-01  8.46686963e-02  2.25922659e-01\n","   2.77846447e-01  1.37081188e-01  1.47138886e-01 -3.17248249e-01\n","  -3.58643777e-01 -3.68748766e-01  7.58767576e-02 -2.71766611e-01\n","   1.16787816e-01  7.11258653e-02  1.34528006e-01 -2.21232617e-02\n","  -4.45993695e-02  4.78860114e-01  3.88493595e-01  4.29301637e-01\n","   3.13912742e-01  1.75511439e-01  9.57190980e-02  3.39533281e-01\n","   3.39345162e-02  6.31824628e-02 -3.75318079e-01 -4.98158385e-01\n","  -1.16710475e-01 -3.01675864e-01  4.05935986e-01 -3.81624500e-01\n","  -1.33828510e-01 -1.72841732e-01  1.79708729e-01  8.41862672e-02\n","   3.11108334e-01  3.23986927e-01  1.50745516e-01 -5.85973423e-04]\n"," [ 1.38654556e-01  4.17033646e-01 -1.43079825e-01  1.16708979e-01\n","  -1.45527629e-01  3.55378574e-02  1.90500407e-01 -6.91894419e-02\n","   2.03674374e-01 -2.46533709e-01 -1.34262893e-01 -2.43590233e-01\n","  -4.56759531e-01 -3.25887801e-01  6.99920391e-02 -3.19143784e-01\n","   1.43680290e-01  1.54237782e-01  5.88624738e-01  1.43288892e-01\n","   2.33043749e-01  5.48590935e-01  2.21682230e-01  2.18870622e-01\n","   1.67023203e-01  5.46158805e-01  3.84747664e-01  2.49920862e-01\n","   2.35423205e-01 -2.03337178e-01 -2.28648977e-03 -2.13955402e-01\n","  -2.94900861e-01  9.29630384e-02  8.11622508e-02 -8.35116584e-02\n","   4.94471546e-02 -4.00221158e-01  2.56719811e-02 -5.77404375e-01\n","  -2.15416731e-01 -4.13428720e-01 -2.87073448e-01 -1.69749064e-02\n","  -5.00506631e-02 -1.95903867e-01  4.13456758e-02 -6.77522092e-02\n","   2.86113028e-03  2.54111774e-01  1.83936711e-01  2.77467661e-01\n","  -3.41998067e-02 -3.34763301e-01 -1.50920964e-01  1.84432555e-02\n","  -1.62930628e-01 -5.56185810e-02 -2.24239048e-02  4.05559866e-02\n","   1.83542649e-01  6.21411267e-01  4.00056765e-01  9.47830234e-02\n","  -7.08919182e-02 -7.17166730e-02 -1.36391443e-01 -4.62135984e-01\n","   2.30274732e-01 -4.82059876e-01 -1.04813245e-01  1.21901854e-01\n","   1.64299437e-01  4.43615684e-01  5.60014857e-01  4.95231948e-01\n","   6.25437115e-01  2.81357242e-01  1.43632751e-01  3.88160804e-01\n","   1.72331492e-01  3.62314857e-01 -1.51985203e-01 -2.68715447e-01\n","  -2.02397674e-01 -7.91126995e-01 -4.35149112e-01 -5.99343066e-01\n","  -3.85296649e-01 -2.29317284e-01  3.55007312e-01 -4.90993838e-03\n","  -2.56952130e-01 -8.68554453e-02  2.03789009e-01 -2.23288734e-01\n","   1.59188308e-01 -1.13616660e-01 -2.70566903e-01  2.27380634e-01]\n"," [ 6.03997800e-01  7.56735623e-01  3.14316969e-01  2.36269903e-01\n","   4.16249930e-01  4.77569771e-01  1.90830629e-03  4.96791961e-02\n","  -1.61317692e-03 -4.87945877e-01 -2.82134185e-01 -2.07559498e-01\n","   3.30339612e-02 -4.11629230e-01 -6.65292316e-02 -1.93419780e-01\n","  -2.92647983e-01  2.52593162e-01  1.10307010e-01  2.97113346e-02\n","   2.06660687e-01  3.01230725e-01  7.75004881e-02  2.26880130e-01\n","  -9.46003251e-02  4.51899606e-01  1.59044564e-01  1.34892319e-01\n","  -2.91952435e-02  2.37883066e-02 -2.37735576e-01 -8.34738320e-03\n","  -4.86685152e-02 -5.28643556e-01 -6.19579511e-01 -1.96046485e-01\n","  -4.73383045e-01 -4.70108989e-01 -2.60890332e-01 -2.78131492e-02\n","   3.36719498e-02  3.26884686e-01 -3.39276401e-01  1.42453711e-01\n","  -8.25481293e-04 -3.88465624e-01 -8.19381844e-02 -6.81302939e-02\n","   1.54741315e-01 -2.39561188e-01 -3.58423134e-01 -1.37383102e-01\n","  -1.58292215e-02 -8.36861057e-02 -3.29221960e-01  6.11007834e-01\n","   2.64563041e-02  1.31260745e-01  6.64873752e-01  5.62067254e-01\n","   6.27042267e-01  1.12449203e-01  1.74227684e-01  9.26387382e-02\n","  -1.33366612e-01  3.40936420e-01  1.68149639e-01 -4.40650580e-01\n","   2.21820167e-01 -6.58202508e-02 -3.29687908e-01  1.05456262e-02\n","   3.32769146e-01  1.15784246e-01  6.21139649e-02  3.51041342e-01\n","  -2.07387866e-02  1.28094212e-01  1.05853411e-01  6.21815142e-02\n","   5.96913164e-02 -1.09382924e-02  2.55955231e-02 -1.94314769e-01\n","   1.19581815e-01  3.01161147e-02  2.34997097e-02 -4.90204543e-01\n","  -4.91022371e-02 -1.66222366e-02 -6.23284361e-02  1.80196295e-01\n","  -3.73743411e-01 -3.13954964e-01 -4.62347720e-01 -4.71828373e-01\n","  -9.06802428e-02  7.82739396e-04 -9.94616755e-02  3.88874715e-01]]\n"]},{"output_type":"stream","name":"stderr","text":["2021-09-15 11:35:24,848 - Creating Validation dataloader\n","2021-09-15 11:35:25,011 - Your dataset is ready !!\n"]},{"output_type":"stream","name":"stdout","text":["Test shape with SNR - 0 (15000, 2, 8, 100)\n","Test shape with SNR - 0 Value [[[-0.18331751 -0.18538722 -0.51912701 ... -0.16079812 -0.01516988\n","   -0.39158001]\n","  [-0.1483578  -0.46139644 -0.25398578 ... -0.07743006  0.14239097\n","   -0.16766948]\n","  [-0.05190266  0.2863506  -0.22475407 ...  0.26566458  0.13209331\n","    0.18457145]\n","  ...\n","  [-0.03204834  0.07050797  0.13975178 ...  0.18967662 -0.12150005\n","    0.36633943]\n","  [ 0.12593894  0.48831969  0.0630564  ...  0.38112657  0.43021043\n","    0.16175566]\n","  [ 0.53663963  0.06546942 -0.17961433 ...  0.16001499  0.44146835\n","    0.25260476]]\n","\n"," [[ 0.07328535  0.12887232 -0.12679827 ...  0.08495302  0.6203703\n","    0.05373103]\n","  [ 0.03114386 -0.12824831 -0.36708215 ...  0.46970888  0.31747035\n","   -0.18927706]\n","  [ 0.03237796 -0.06081181 -0.39205188 ... -0.07389897  0.23021817\n","   -0.00887957]\n","  ...\n","  [ 0.036944    0.03159906 -0.24405103 ...  0.38408729  0.27381406\n","    0.09865278]\n","  [-0.34077923  0.32664081  0.21532337 ... -0.04029427  0.26108615\n","    0.04674723]\n","  [ 0.3661846   0.36445751  0.07285676 ... -0.53976506  0.53316605\n","    0.03115836]]]\n"]}]},{"cell_type":"code","metadata":{"id":"nPCXqnMlNAo-"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c6aGZIVyNBGp"},"source":["#resnet 34"]},{"cell_type":"code","metadata":{"id":"ayf3uCjmMPmf"},"source":["model = torchvision.models.resnet34(pretrained=False)\n","\n","# Removed last two layers\n","ResNet34 = torch.nn.Sequential(*(list(model.children())[:-2]))\n","# Changed the input channel to 2\n","ResNet34[0] = nn.Conv2d(2, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","ResNet34.avgpool = nn.AdaptiveAvgPool2d((no_doa, 150))\n","ResNet34.fc = nn.Linear(150, 181)\n","ResNet34.flat = nn.Conv2d(in_channels=512, out_channels=1, kernel_size=1, stride=1)\n","# print(ResNet34)\n","\n","if __name__ == \"__main__\":\n","    image = torch.rand(64, 2, 10, 100)\n","    \n","    print(ResNet34(image).size())\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wInuYTaYS6B2"},"source":["class FocalLoss(nn.modules.loss._WeightedLoss):\n","    def __init__(self, weight=None, gamma=2,reduction='mean'):\n","        super(FocalLoss, self).__init__(weight,reduction=reduction)\n","        self.gamma = gamma\n","        self.weight = weight #weight parameter will act as the alpha parameter to balance class weights\n","\n","    def forward(self, input, target):\n","        ce_loss = F.cross_entropy(input, target,reduction=self.reduction,weight=self.weight)\n","        pt = torch.exp(-ce_loss)\n","        focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n","        return focal_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HWnVoRaYizWQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631545902194,"user_tz":-330,"elapsed":11,"user":{"displayName":"Mohammad Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1sqT9k-ZJhDQXM7x7dup6__HgCR7MEKRseC9t6w=s64","userId":"07657306696827110934"}},"outputId":"eeb2e1d4-1b07-41cc-a714-8ecdb3759424"},"source":["num_epochs = 70\n","\n","weights_dir = (\"/content/drive/MyDrive/DOA/{}/weights\".format(nq_type, no_samples))\n","doa =7\n","autoencoder = ResNet34\n","criterion = nn.CrossEntropyLoss()\n","focal_criterion = FocalLoss()\n","\n","# if (\"SNS_DOA_7_200_model_2.pth\" in [f for f in listdir(weights_dir) if isfile(join(weights_dir, f))]):\n","#     print(\"Pre-trained available for DOA_{}_{}_model_2.pth\".format(no_doa, no_samples))\n","#     autoencoder = torch.load(os.path.join(weights_dir, \"/content/drive/MyDrive/DOA/NS/weights/SNS_DOA_7_200_model_2.pth\"))\n","\n","if torch.cuda.is_available():\n","  print(torch.cuda.get_device_name(0))\n","  classification_model = autoencoder.cuda()\n","  optimizer = optim.AdamW(classification_model.parameters(), lr=0.001, weight_decay=1e-4)\n","  \n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\", factor=0.05, patience=5, verbose=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tesla P100-PCIE-16GB\n"]}]},{"cell_type":"code","metadata":{"id":"isXcaOBri3fQ"},"source":["acc_res = {\n","    \"training\": [],\n","    0: [],\n","    10: [],\n","    20: [],\n","    30: [],\n","    40: []\n","}\n","loss_res = {\n","    \"training\": [],\n","    0: [],\n","    10: [],\n","    20: [],\n","    30: [],\n","    40: []\n","}\n","mae_res = {\n","    \"training\": [],\n","    0: [],\n","    10: [],\n","    20: [],\n","    30: [],\n","    40: []\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ukzT7V0CpUmG","executionInfo":{"status":"error","timestamp":1631547030678,"user_tz":-330,"elapsed":4585,"user":{"displayName":"Mohammad Ahmad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1sqT9k-ZJhDQXM7x7dup6__HgCR7MEKRseC9t6w=s64","userId":"07657306696827110934"}},"outputId":"c2ffc60d-583c-4f82-ffb5-f0e08902e2fe"},"source":["%%time\n","def train():\n","    print(\"Training Starts !!!!!!!\")\n","    best_valid_loss = float('Inf')\n","    for i in range(num_epochs):\n","        training_loss = 0\n","        train_correct = 0\n","        train_total = 0\n","        epoch_loss = 0.0\n","        training_mae = 0.0\n","        classification_model.train()\n","        for j,(features, labels) in enumerate(doa_train_loader):\n","            print(\"train\", features.size(), labels.size())\n","            \n","            features, labels = Variable(features.cuda()), Variable(labels.cuda())\n","            optimizer.zero_grad()\n","\n","            enn = classification_model(features.float())\n","            print(\"Output\", enn.size())\n","            auto_outputs = torch.transpose(enn, 2, 3)\n","            auto_outputs = torch.reshape(auto_outputs.cuda(), (auto_outputs.shape[0], 181, doa))\n","            print(\"Output after reshape\", auto_outputs.size())\n","            losss = criterion(auto_outputs.cuda(), labels.type(torch.LongTensor).cuda())\n","            losss.backward()\n","            optimizer.step()\n","#           exp_scheduler.step()\n","            training_loss += losss.item()\n","\n","            _, pred = torch.max(auto_outputs, 1)\n","\n","            print(\"pred\",pred.size())\n","            print(\"Pred Vale\", pred[0], \"Labels value\",labels[0])\n","            train_total+= labels.reshape(-1).size(0)\n","\n","            train_correct+=(pred.reshape(-1).cuda() == labels.reshape(-1)).sum().item()\n","\n","            epoch_loss += auto_outputs.shape[0] * losss.item()\n","            training_mae += torch.abs(pred.reshape(-1).cuda() - labels.reshape(-1)).sum().item()  \n","\n","        loss_res['training'].append(training_loss/len(doa_train_loader))\n","        acc_res['training'].append((100*(train_correct/train_total)))\n","        mae_res['training'].append(training_mae/(64*len(doa_train_loader)*181*7))\n","        print('Epoch [{}/{}], Training Loss: {:.4f}, Training Accuracy: {:.4f}, Training MAE: {}'\n","                      .format(i+1, num_epochs, training_loss/len(doa_train_loader), (100*(train_correct/train_total)), training_mae/(len(doa_train_loader)*64*7*181)))\n","        \n","        # Validation for each SNR value\n","        classification_model.eval()\n","        total_valdation_loss = 0\n","        for val_data in range(0, len(test_dataset_list)):\n","            print(\"test\", features.size(), labels.size())\n","            validation_loss = 0\n","            validation_acc = 0\n","            validation_mae = 0.0\n","            val_correct = 0\n","            val_total = 0\n","\n","            with torch.no_grad():\n","                for features, labels in test_dataset_list[val_data]:\n","                    features, labels = Variable(features.cuda()), Variable(labels.cuda())\n","                    enn = classification_model(features.float())\n","                    auto_outputs = torch.transpose(enn, 2, 3)\n","                    auto_outputs = torch.reshape(auto_outputs, (auto_outputs.shape[0], 181, doa))\n","                    loss = criterion(auto_outputs.cuda(), labels.type(torch.LongTensor).cuda())\n","\n","                    _, pred = torch.max(auto_outputs, 1)\n","                    val_total+= labels.reshape(-1).size(0)\n","                    val_correct+=(pred.reshape(-1).cuda() == labels.reshape(-1)).sum().item()\n","                    validation_loss += loss.item()\n","                    validation_mae += torch.abs(pred.reshape(-1).cuda() - labels.reshape(-1)).sum().item()\n","\n","                loss_res[10*val_data].append(validation_loss/len(test_dataset_list[val_data]))\n","                acc_res[10*val_data].append((100*(val_correct/val_total)))\n","                \n","                mae_res[10*val_data].append(validation_mae/(128*len(test_dataset_list[val_data])*181*7))\n","                print('SNR [{}dB], Validation Loss: {:.4f}, Validation Accuracy: {:.4f}, Validation MAE: {}'\n","                      .format(val_data*10, validation_loss/len(test_dataset_list[val_data]), (100*(val_correct/val_total)), validation_mae/(len(test_dataset_list[val_data])*7*128*181)))\n","\n","                total_valdation_loss+=validation_loss\n","            torch.save( classification_model, weights_dir+ \"/SNS_DOA_{}_100_model_2.pth\".format(doa))\n","            if best_valid_loss > total_valdation_loss:\n","                best_valid_loss = total_valdation_loss \n","                # Saving Best Pre-Trained Model as .pth file\n","                torch.save( classification_model, weights_dir+ \"/DOA_{}_100_best_model_2.pth\".format(doa))\n","#         if i%10 == 0:\n","#           ddf = pd.DataFrame(acc_res)\n","#           ddf.to_csv(weights_dir+\"res_DOA_{}_model.csv\".format(doa))\n","        print(\"\\n\")  \n","\n","train()\n","print(\"Training Complete\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Starts !!!!!!!\n","train torch.Size([64, 3, 8, 100]) torch.Size([64, 7])\n","Output torch.Size([64, 1, 7, 181])\n","Output reshape torch.Size([64, 181, 7])\n","torch.Size([64, 7]) tensor([0.8054, 0.6765, 0.7167, 0.7892, 0.9072, 0.5613, 1.2575],\n","       device='cuda:0', grad_fn=<SelectBackward>)\n","pred torch.Size([64, 7])\n","tensor([ 65, 173, 130,  68, 140,  53,  38], device='cuda:0') tensor([ 88.,  33., 172.,  80.,  89., 125., 103.], device='cuda:0',\n","       dtype=torch.float64)\n","train torch.Size([64, 3, 8, 100]) torch.Size([64, 7])\n","Output torch.Size([64, 1, 7, 181])\n","Output reshape torch.Size([64, 181, 7])\n","torch.Size([64, 7]) tensor([0.8095, 0.6304, 0.7979, 0.8163, 0.9067, 0.9587, 1.2121],\n","       device='cuda:0', grad_fn=<SelectBackward>)\n","pred torch.Size([64, 7])\n","tensor([ 63, 179, 160,  47, 152,  21, 150], device='cuda:0') tensor([138., 118.,  70.,  78., 108.,  27.,  93.], device='cuda:0',\n","       dtype=torch.float64)\n","train torch.Size([64, 3, 8, 100]) torch.Size([64, 7])\n","Output torch.Size([64, 1, 7, 181])\n","Output reshape torch.Size([64, 181, 7])\n","torch.Size([64, 7]) tensor([0.6771, 0.6243, 0.7102, 0.6965, 0.8886, 1.0029, 1.3188],\n","       device='cuda:0', grad_fn=<SelectBackward>)\n","pred torch.Size([64, 7])\n","tensor([145,  21, 125, 112, 174,  14, 176], device='cuda:0') tensor([178., 151., 150., 177.,  11.,  16.,   1.], device='cuda:0',\n","       dtype=torch.float64)\n","train torch.Size([64, 3, 8, 100]) torch.Size([64, 7])\n","Output torch.Size([64, 1, 7, 181])\n","Output reshape torch.Size([64, 181, 7])\n","torch.Size([64, 7]) tensor([0.8124, 0.5696, 1.0491, 0.7714, 1.0381, 0.7827, 1.3558],\n","       device='cuda:0', grad_fn=<SelectBackward>)\n","pred torch.Size([64, 7])\n","tensor([153, 161, 165, 128, 160, 136,  16], device='cuda:0') tensor([160.,  76.,  89., 162.,  59.,   3., 135.], device='cuda:0',\n","       dtype=torch.float64)\n","train torch.Size([64, 3, 8, 100]) torch.Size([64, 7])\n","Output torch.Size([64, 1, 7, 181])\n","Output reshape torch.Size([64, 181, 7])\n","torch.Size([64, 7]) tensor([1.0114, 0.6089, 0.8047, 0.6940, 0.8786, 0.9595, 1.3938],\n","       device='cuda:0', grad_fn=<SelectBackward>)\n","pred torch.Size([64, 7])\n","tensor([165, 167,  83, 158, 101, 162,  52], device='cuda:0') tensor([ 70., 175., 168., 105.,  28., 126., 124.], device='cuda:0',\n","       dtype=torch.float64)\n","train torch.Size([64, 3, 8, 100]) torch.Size([64, 7])\n","Output torch.Size([64, 1, 7, 181])\n","Output reshape torch.Size([64, 181, 7])\n","torch.Size([64, 7]) tensor([0.9645, 0.5932, 0.6365, 0.6853, 0.9403, 1.0517, 1.2898],\n","       device='cuda:0', grad_fn=<SelectBackward>)\n","pred torch.Size([64, 7])\n","tensor([160, 175,   4, 164,  91, 165, 105], device='cuda:0') tensor([ 40.,  82., 160.,  42., 137.,   2., 156.], device='cuda:0',\n","       dtype=torch.float64)\n","train torch.Size([64, 3, 8, 100]) torch.Size([64, 7])\n","Output torch.Size([64, 1, 7, 181])\n","Output reshape torch.Size([64, 181, 7])\n","torch.Size([64, 7]) tensor([0.8845, 0.5965, 0.8356, 0.5691, 0.8452, 0.7606, 1.0962],\n","       device='cuda:0', grad_fn=<SelectBackward>)\n","pred torch.Size([64, 7])\n","tensor([ 30,  56,  70,  33,  79,  13, 142], device='cuda:0') tensor([ 47., 124., 170., 133., 180., 148.,  12.], device='cuda:0',\n","       dtype=torch.float64)\n","train torch.Size([64, 3, 8, 100]) torch.Size([64, 7])\n","Output torch.Size([64, 1, 7, 181])\n","Output reshape torch.Size([64, 181, 7])\n","torch.Size([64, 7]) tensor([0.8641, 0.4949, 0.6232, 0.7016, 0.7967, 0.8604, 0.8700],\n","       device='cuda:0', grad_fn=<SelectBackward>)\n","pred torch.Size([64, 7])\n","tensor([  7,  56, 135, 165, 103, 111,  96], device='cuda:0') tensor([ 25., 170.,  88., 102., 109., 154.,  96.], device='cuda:0',\n","       dtype=torch.float64)\n","train torch.Size([64, 3, 8, 100]) torch.Size([64, 7])\n","Output torch.Size([64, 1, 7, 181])\n","Output reshape torch.Size([64, 181, 7])\n","torch.Size([64, 7]) tensor([0.6445, 0.5468, 0.6966, 0.6094, 0.9754, 0.7697, 1.3756],\n","       device='cuda:0', grad_fn=<SelectBackward>)\n","pred torch.Size([64, 7])\n","tensor([124,  53, 180,  35,  50, 132,  22], device='cuda:0') tensor([ 62., 129., 180.,  39., 119., 112.,  58.], device='cuda:0',\n","       dtype=torch.float64)\n","train torch.Size([64, 3, 8, 100]) torch.Size([64, 7])\n","Output torch.Size([64, 1, 7, 181])\n","Output reshape torch.Size([64, 181, 7])\n","torch.Size([64, 7]) tensor([0.8377, 0.7618, 0.7801, 0.4861, 0.7695, 0.8325, 0.9571],\n","       device='cuda:0', grad_fn=<SelectBackward>)\n","pred torch.Size([64, 7])\n","tensor([ 15,  70,  15,  93, 146,   8, 112], device='cuda:0') tensor([ 56.,   9.,  85., 131., 160., 112.,  10.], device='cuda:0',\n","       dtype=torch.float64)\n","train torch.Size([64, 3, 8, 100]) torch.Size([64, 7])\n","Output torch.Size([64, 1, 7, 181])\n","Output reshape torch.Size([64, 181, 7])\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-24c9e477ed02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'def train():\\n    print(\"Training Starts !!!!!!!\")\\n    best_valid_loss = float(\\'Inf\\')\\n    for i in range(num_epochs):\\n        training_loss = 0\\n        train_correct = 0\\n        train_total = 0\\n        epoch_loss = 0.0\\n        training_mae = 0.0\\n        classification_model.train()\\n        for j,(features, labels) in enumerate(doa_train_loader):\\n            print(\"train\", features.size(), labels.size())\\n            \\n            features, labels = Variable(features.cuda()), Variable(labels.cuda())\\n            optimizer.zero_grad()\\n\\n            enn = classification_model(features.float())\\n            print(\"Output\", enn.size())\\n            auto_outputs = torch.transpose(enn, 2, 3)\\n            auto_outputs = torch.reshape(auto_outputs.cuda(), (auto_outputs.shape[0], 181, doa))\\n            print(\"Output reshape\", auto_outputs.size())\\n            losss = criterion(auto_outputs.cuda(), labels.type(torch.LongTensor).cuda())\\n            losss.backward()\\n            optimizer.step()\\n#           exp_scheduler.step()\\n            training_loss += losss.item()\\n\\n            a, pred = torch.max(auto_outputs, 1)\\n            print(a.size(), a[0])\\n            print(\"pred\",pred.size())\\n            print(pred[0], labels[0])\\n            train_total+= labels.reshape(-1).size(0)\\n\\n          ...\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"JpWJ4cR_i5qy"},"source":["%%time\n","def train():\n","    print(\"Training Starts !!!!!!!\")\n","    best_valid_loss = float('Inf')\n","    for i in range(num_epochs):\n","        training_loss = 0\n","        train_correct = 0\n","        train_total = 0\n","        epoch_loss = 0.0\n","        training_mae = 0.0\n","        classification_model.train()\n","        for j,(features, labels) in enumerate(doa_train_loader, 0):\n","            features, labels = Variable(features.cuda()), Variable(labels.cuda())\n","            optimizer.zero_grad()\n","            enn = classification_model(features.float())\n","            auto_outputs = torch.transpose(enn, 2, 3)\n","            auto_outputs = torch.reshape(auto_outputs.cuda(), (auto_outputs.shape[0], 181, doa))\n","            losss = criterion(auto_outputs.cuda(), labels.type(torch.LongTensor).cuda())\n","            losss.backward()\n","            optimizer.step()\n","#           exp_scheduler.step()\n","            training_loss += losss.item()\n","\n","            _, pred = torch.max(auto_outputs, 1)\n","\n","            train_total+= labels.reshape(-1).size(0)\n","\n","            train_correct+=(pred.reshape(-1).cuda() == labels.reshape(-1)).sum().item()\n","\n","            epoch_loss += auto_outputs.shape[0] * losss.item()\n","            training_mae += torch.abs(pred.reshape(-1).cuda() - labels.reshape(-1)).sum().item()  \n","\n","        loss_res['training'].append(training_loss/len(doa_train_loader))\n","        acc_res['training'].append((100*(train_correct/train_total)))\n","        mae_res['training'].append(training_mae/(64*len(doa_train_loader)*181))\n","        print('Epoch [{}/{}], Training Loss: {:.4f}, Training Accuracy: {:.4f}, Training MAE: {}'\n","                      .format(i+1, num_epochs, training_loss/len(doa_train_loader), (100*(train_correct/train_total)), training_mae/(len(doa_train_loader)*64*181)))\n","        \n","        # Validation for each SNR value\n","        classification_model.eval()\n","        total_valdation_loss = 0\n","        for val_data in range(0, len(test_dataset_list)):\n","            \n","            validation_loss = 0\n","            validation_acc = 0\n","            validation_mae = 0.0\n","            val_correct = 0\n","            val_total = 0\n","\n","            with torch.no_grad():\n","                for features, labels in test_dataset_list[val_data]:\n","                    features, labels = Variable(features.cuda()), Variable(labels.cuda())\n","                    enn = classification_model(features.float())\n","                    auto_outputs = torch.transpose(enn, 2, 3)\n","                    auto_outputs = torch.reshape(auto_outputs, (auto_outputs.shape[0], 181, doa))\n","                    loss = criterion(auto_outputs.cuda(), labels.type(torch.LongTensor).cuda())\n","\n","                    _, pred = torch.max(auto_outputs, 1)\n","                    val_total+= labels.reshape(-1).size(0)\n","                    val_correct+=(pred.reshape(-1).cuda() == labels.reshape(-1)).sum().item()\n","                    validation_loss += loss.item()\n","                    validation_mae += torch.abs(pred.reshape(-1).cuda() - labels.reshape(-1)).sum().item()\n","\n","                loss_res[10*val_data].append(validation_loss/len(test_dataset_list[val_data]))\n","                acc_res[10*val_data].append((100*(val_correct/val_total)))\n","                \n","                mae_res[10*val_data].append(validation_mae/(128*len(test_dataset_list[val_data])*181))\n","                print('SNR [{}dB], Validation Loss: {:.4f}, Validation Accuracy: {:.4f}, Validation MAE: {}'\n","                      .format(val_data*10, validation_loss/len(test_dataset_list[val_data]), (100*(val_correct/val_total)), validation_mae/(len(test_dataset_list[val_data])*128*181)))\n","\n","                total_valdation_loss+=validation_loss\n","            torch.save( classification_model, weights_dir+ \"/SNS_DOA_{}_200_model.pth\".format(doa))\n","            if best_valid_loss > total_valdation_loss:\n","                best_valid_loss = total_valdation_loss \n","                # Saving Best Pre-Trained Model as .pth file\n","                torch.save( classification_model, weights_dir+ \"/DOA_{}_200_best_model.pth\".format(doa))\n","#         if i%10 == 0:\n","#           ddf = pd.DataFrame(acc_res)\n","#           ddf.to_csv(weights_dir+\"res_DOA_{}_model.csv\".format(doa))\n","        print(\"\\n\")  \n","\n","train()\n","print(\"Training Complete\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fSy9baMBB42"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eJKGYM8fxCc0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YVUmpeEQGzJG"},"source":["# UNet"]},{"cell_type":"code","metadata":{"id":"3CfOvO9HG0qR"},"source":["import torch\n","import torch.nn as nn\n","from torch.nn import init\n","\n","def single_conv(in_c, out_c):\n","    conv = nn.Sequential(\n","        nn.Conv2d(in_c, out_c, kernel_size=3, stride=1, padding=1, bias=True),\n","        nn.BatchNorm2d(out_c),\n","        nn.ReLU(inplace=True))\n","    return conv\n","\n","def double_conv1(in_c, out_c):\n","    conv = nn.Sequential(\n","        nn.Conv2d(in_c, out_c, kernel_size=(3,2),padding=1 ,stride=1, bias=True),\n","        nn.BatchNorm2d(out_c),\n","        nn.ReLU(inplace=True),\n","        nn.Conv2d(out_c, out_c, kernel_size=(3,2),stride=1, bias=True),\n","        nn.BatchNorm2d(out_c),\n","        nn.ReLU(inplace=True))\n","    return conv\n","\n","def double_conv2(in_c, out_c):\n","    conv = nn.Sequential(\n","        nn.Conv2d(in_c, out_c, kernel_size=(3,3),padding=1 ,stride=1, bias=True),\n","        nn.BatchNorm2d(out_c),\n","        nn.ReLU(inplace=True),\n","        nn.Conv2d(out_c, out_c, kernel_size=(3,3), padding=1 ,stride=1, bias=True),\n","        nn.BatchNorm2d(out_c),\n","        nn.ReLU(inplace=True))\n","    return conv\n","\n","\n","def up_conv1(in_c, out_c):\n","    conv = nn.Sequential(\n","        nn.ConvTranspose2d(in_c, out_c, kernel_size=(2, 2), stride=2))\n","    return conv\n","    \n","def up_conv2(in_c, out_c):\n","    conv = nn.Sequential(\n","        nn.ConvTranspose2d(in_c, out_c, kernel_size=(2,2), stride=2))\n","    return conv\n","\n","\n","class Recurrent_block(nn.Module):\n","    def __init__(self,ch_out,t=2):\n","        super(Recurrent_block,self).__init__()\n","        self.t = t\n","        self.ch_out = ch_out\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n","\t\t    nn.BatchNorm2d(ch_out),\n","\t\t\tnn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self,x):\n","        for i in range(self.t):\n","\n","            if i==0:\n","                x1 = self.conv(x)\n","            \n","            x1 = self.conv(x+x1)\n","        return x1\n","\n","class RRCNN_block(nn.Module):\n","    def __init__(self,ch_in,ch_out,t=2):\n","        super(RRCNN_block,self).__init__()\n","        self.RCNN = nn.Sequential(\n","            Recurrent_block(ch_out,t=t),\n","            Recurrent_block(ch_out,t=t)\n","        )\n","        self.Conv_1x1 = nn.Conv2d(ch_in,ch_out,kernel_size=1,stride=1,padding=0)\n","\n","    def forward(self,x):\n","        x = self.Conv_1x1(x)\n","        x1 = self.RCNN(x)\n","        return x+x1\n","\n","\n","class Attention_block(nn.Module):\n","    def __init__(self,F_g,F_l,F_int):\n","        super(Attention_block,self).__init__()\n","        self.W_g = nn.Sequential(\n","            nn.Conv2d(F_g, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n","            nn.BatchNorm2d(F_int)\n","            )\n","        \n","        self.W_x = nn.Sequential(\n","            nn.Conv2d(F_l, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n","            nn.BatchNorm2d(F_int)\n","        )\n","\n","        self.psi = nn.Sequential(\n","            nn.Conv2d(F_int, 1, kernel_size=1,stride=1,padding=0,bias=True),\n","            nn.BatchNorm2d(1),\n","            nn.Sigmoid()\n","        )\n","        \n","        self.relu = nn.ReLU(inplace=True)\n","        \n","    def forward(self,g,x):\n","        g1 = self.W_g(g)\n","        x1 = self.W_x(x)\n","        psi = self.relu(g1+x1)\n","        psi = self.psi(psi)\n","\n","        return x*psi\n","\n","class Encoder(nn.Module):\n","    def __init__(self,img_ch=3,output_ch=3,t=2):\n","        super(Encoder, self).__init__()\n","        self.max_pool_2x2 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.RCNN1 = RRCNN_block(img_ch, 64, t=t)\n","        self.RCNN2 = RRCNN_block(64, 128, t=t)\n","        self.RCNN3 = RRCNN_block(128, 256, t=t)\n","        self.dropout = nn.Dropout(p=0.3)\n","\n","    def forward(self, image):\n","        # encoder\n","        x1 = self.RCNN1(image)\n","        x2 = self.max_pool_2x2(x1)\n","        x3 = self.RCNN2(x2)\n","        x3 = self.dropout(x3)\n","        x4 = self.max_pool_2x2(x3)\n","        x5 = self.RCNN3(x4)\n","        x5 = self.dropout(x5)\n","        return x1, x2, x3, x4, x5\n","\n","class Decoder(nn.Module):\n","    def __init__(self,img_ch=3,output_ch=3,t=2):\n","        super(Decoder, self).__init__()\n","        self.up_trans_1 = up_conv1(256, 128)\n","        self.Att1 = Attention_block(F_g=128,F_l=128,F_int=64)\n","        self.Up_RRCNN1 = RRCNN_block(256, 128,t=t)\n","        \n","        self.up_trans_2 = up_conv2(128, 64)\n","        self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n","        self.Up_RRCNN2 = RRCNN_block(128, 64,t=t)\n","        self.dropout = nn.Dropout(p=0.3)\n","        self.out = nn.Conv2d(\n","            in_channels=64,\n","            out_channels=output_ch,\n","            kernel_size=1,stride=1,padding=0)\n","        \n","    def forward(self, image):\n","        x1, x2, x3, x4, x5 = image[0], image[1], image[2], image[3], image[4]\n","        # decoder\n","        x = self.up_trans_1(x5)\n","        x3 = nn.functional.interpolate(x3, (x.size()[2], x.size()[3]))\n","        x3 = self.Att1(g=x,x=x3)\n","        x = self.Up_RRCNN1(torch.cat([x, x3], 1))\n","        x = self.dropout(x)\n","\n","        x = self.up_trans_2(x)\n","        x1 = nn.functional.interpolate(x1, (x.size()[2], x.size()[3]))\n","        x1 = self.Att2(g=x,x=x1)\n","        x = self.Up_RRCNN2(torch.cat([x, x1], 1))\n","        x = self.dropout(x)\n","        x = self.out(x)\n","        return x\n","\n","class Att_R2U(nn.Module):\n","    def __init__(self,img_ch=3,output_ch=3,t=2):\n","        super(Att_R2U, self).__init__()\n","        self.encoder = Encoder(img_ch=3,output_ch=3,t=2)\n","        self.decoder = Decoder(img_ch=3,output_ch=3,t=2)\n","\n","    def forward(self, image):\n","        # encoder\n","        x1, x2, x3, x4, x5 = self.encoder(image)\n","        # decoder\n","        x = self.decoder([x1, x2, x3, x4, x5])\n","        return x\n","\n","\n","\n","if __name__ == \"__main__\":\n","#     print(\"start\")\n","    image = torch.rand(1, 3, 8, 100)\n","    model = Att_R2U()\n","    print(model.encoder(image)[-1].size())\n","    print(model(image).size())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WRzHWjPUG2V2"},"source":["import torch\n","import torch.nn as nn\n","from torch.nn import init\n","\n","class Recurrent_block(nn.Module):\n","    def __init__(self,ch_out,t=2):\n","        super(Recurrent_block,self).__init__()\n","        self.t = t\n","        self.ch_out = ch_out\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n","\t\t    nn.BatchNorm2d(ch_out),\n","\t\t\tnn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self,x):\n","        for i in range(self.t):\n","\n","            if i==0:\n","                x1 = self.conv(x)\n","            \n","            x1 = self.conv(x+x1)\n","        return x1\n","\n","class RRCNN_block(nn.Module):\n","    def __init__(self,ch_in,ch_out,t=2):\n","        super(RRCNN_block,self).__init__()\n","        self.RCNN = nn.Sequential(\n","            Recurrent_block(ch_out,t=t),\n","            Recurrent_block(ch_out,t=t)\n","        )\n","        self.Conv_1x1 = nn.Conv2d(ch_in,ch_out,kernel_size=1,stride=1,padding=0)\n","\n","    def forward(self,x):\n","        x = self.Conv_1x1(x)\n","        x1 = self.RCNN(x)\n","        return x+x1\n","\n","class Classifer(nn.Module):\n","    def __init__(self,img_ch=256,output_ch=3,t=2):\n","        super(Classifer, self).__init__()\n","        self.max_pool_2x2 = nn.MaxPool2d(kernel_size=1, stride=1)\n","        self.RCNN1 = RRCNN_block(img_ch, 128, t=t)\n","        self.RCNN2 = RRCNN_block(128, 64, t=t)\n","        self.RCNN3 = RRCNN_block(64, 32, t=t)\n","        self.linear = nn.Linear(150, 181)\n","        self.adp_pool = nn.AdaptiveMaxPool2d((7, 150))\n","        #self.flat = nn.Conv2d(in_channels=512, out_channels=1, kernel_size=1, stride=1)\n","        self.flat = nn.Conv2d(in_channels=64, out_channels=1, kernel_size=1, stride=1)\n","        self.dropout = nn.Dropout(p=0.3)\n","        self.out = nn.Conv2d(\n","            in_channels=64,\n","            out_channels=output_ch,\n","            kernel_size=1,stride=1,padding=0)\n","\n","    def forward(self, image):\n","        x = self.RCNN1(image)\n","\n","        x = self.RCNN2(x)\n","        x = self.dropout(x)\n","        # x = self.RCNN3(x)\n","        x = self.dropout(x)\n","        x = self.adp_pool(x)\n","        x = self.linear(x)\n","        x = self.flat(x)\n","        return x\n","\n","if __name__ == \"__main__\":\n","#     print(\"start\")\n","    image = torch.rand(1, 3, 8, 100)\n","    unet = Att_R2U()\n","    enco = unet.encoder(image)\n","    model = Classifer()\n","    print(model(enco[-1]).size())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oQ8EgjsqJRDS"},"source":[""],"execution_count":null,"outputs":[]}]}